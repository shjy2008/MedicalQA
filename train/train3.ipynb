{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc5244d-9f82-4556-b3c1-85fc2b6ec2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: /projects/sciences/computing/sheju347/.cache/huggingface\n",
      "HF_HUB_CACHE: /projects/sciences/computing/sheju347/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set env vars BEFORE importing huggingface modules\n",
    "os.environ[\"HF_HOME\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface/hub\"\n",
    "\n",
    "# Now import huggingface modules\n",
    "from huggingface_hub import constants\n",
    "\n",
    "print(\"HF_HOME:\", constants.HF_HOME)\n",
    "print(\"HF_HUB_CACHE:\", constants.HF_HUB_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa615df7-2248-4d64-9b5f-3e657277b82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/sciences/computing/sheju347/miniconda3/envs/LLM311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/projects/sciences/computing/sheju347/miniconda3/envs/LLM311/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# !python model_trainer.py\n",
    "from model_trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40d493f-f94b-43a1-b52b-82bab72afcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2025-12-10 17:22:59.790519\n",
      "---------- start checking GPU -----------\n",
      "GPU: NVIDIA H100 NVL\n",
      "torch.cuda.is_bf16_supported():  True\n",
      "---------- finish checking GPU -----------\n",
      "---------- start loading model:('/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-9-phi3.5-mini-UltraMedical-batchsize8/checkpoint-153600', '/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-9-phi3.5-mini-UltraMedical-batchsize8/') -----------\n",
      "finish loading tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 104.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading model\n",
      "torch_dtype: torch.bfloat16\n",
      "cuda available: True\n",
      "device: cuda\n",
      "---------- finish loading model:/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-9-phi3.5-mini-UltraMedical-batchsize8/checkpoint-153600 -----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "print(\"time:\", datetime.now())\n",
    "\n",
    "# output_dir = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_qwen/11-25-qwen-4B-Thinking-UltraMedical\"\n",
    "# output_dir = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-1-phi3-mini-batchsize8-epoch456\"\n",
    "# output_dir = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_qwen/11-25-qwen-4B-Thinking-batch8-epoch456\"\n",
    "output_dir = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-9-phi3.5-mini-UltraMedical-batchsize8-epoch456\"\n",
    "\n",
    "trainer = ModelTrainer(output_dir = output_dir)\n",
    "\n",
    "# model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# model_name = \"microsoft/Phi-4-mini-instruct\"\n",
    "# model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# model_name = \"google/medgemma-4b-it\"\n",
    "# model_name = \"Qwen/Qwen3-4B-Thinking-2507\"\n",
    "\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/10-15-UltraMedical-batchsize8-bf16/checkpoint-153600\"\n",
    "# tokenizer_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/10-15-UltraMedical-batchsize8-bf16\"\n",
    "\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_qwen/11-25-qwen-4B-Thinking-UltraMedical/checkpoint-153600\"\n",
    "# tokenizer_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_qwen/11-25-qwen-4B-Thinking-UltraMedical\"\n",
    "\n",
    "model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-9-phi3.5-mini-UltraMedical-batchsize8/checkpoint-153600\"\n",
    "tokenizer_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-9-phi3.5-mini-UltraMedical-batchsize8/\"\n",
    "\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/10-15-UltraMedical-batchsize8-bf16\"\n",
    "# model_name = \"google/flan-t5-xl\"\n",
    "# model_name = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "# model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "# model_name = \"Qwen/Qwen2.5-0.5B-instruct\"\n",
    "# model_name = \"KrithikV/MedMobile\"\n",
    "# model_name = \"./saved_models/fine_tuned_model_entire_UltraMedical_batch_4\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_qwen/11-11-Qwen3-4B-base-UltraMedical/checkpoint-307197\"\n",
    "# tokenizer_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_qwen/11-11-Qwen3-4B-base-UltraMedical\"\n",
    "trainer.load_model(model_name, tokenizer_path = tokenizer_path)\n",
    "\n",
    "# trainer.load_model(model_name)\n",
    "# trainer.load_fine_tuned_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bccd806d-c81a-4d04-a677-1efd9f4b7663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- finish loading dataset -----------\n",
      "Dataset({\n",
      "    features: ['id', 'type', 'conversations', 'answer', 'score'],\n",
      "    num_rows: 409593\n",
      "})\n",
      "----------- start preprocessing training data ------------\n",
      "Dataset({\n",
      "    features: ['id', 'type', 'conversations', 'answer', 'score'],\n",
      "    num_rows: 409593\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 409593/409593 [09:46<00:00, 697.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- finish preprocessing training data -----------\n",
      "Dataset({\n",
      "    features: ['id', 'type', 'conversations', 'answer', 'score', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 409593\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # For training\n",
    "trainer.load_dataset()\n",
    "# # trainer.convert_to_tokenized_training_data(trainer.dataset[0])\n",
    "trainer.preprocess_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23671616-d528-44e8-a34c-e321fa0616e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- start training model:/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-9-phi3.5-mini-UltraMedical-batchsize8/checkpoint-153600 ------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='154271' max='307200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [154271/307200 09:24 < 35:50:37, 1.19 it/s, Epoch 3.01/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>153700</td>\n",
       "      <td>0.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153800</td>\n",
       "      <td>0.185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153900</td>\n",
       "      <td>0.177700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154000</td>\n",
       "      <td>0.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154100</td>\n",
       "      <td>0.188700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154200</td>\n",
       "      <td>0.175400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# # Monkey-patch torch.load to disable weights_only check\n",
    "# _original_load = torch.load\n",
    "\n",
    "# def _patched_load(f, *args, **kwargs):\n",
    "#     kwargs['weights_only'] = False\n",
    "#     return _original_load(f, *args, **kwargs)\n",
    "\n",
    "# torch.load = _patched_load\n",
    "\n",
    "\n",
    "trainer.train_model(resume_from_checkpoint = model_name, batch_size = 8, num_train_epochs = 6)\n",
    "# trainer.train_model(batch_size = 8)\n",
    "# trainer.train_model_t5()\n",
    "trainer.save_trained_model()\n",
    "\n",
    "# # # For Testing\n",
    "# trainer.load_fine_tuned_model()\n",
    "# trainer.test_model_MedQA_response()\n",
    "# trainer.test_model_accuracy(DatasetPath.MedMCQA, is_ensemble = False)\n",
    "\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d351b8ee-98c8-4fd8-b8af-f01b138792e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b35bc1-9cbb-4565-9b36-8566a3a65bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM311)",
   "language": "python",
   "name": "llm311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

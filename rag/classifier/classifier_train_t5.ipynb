{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a855791-aa19-49dd-ac5d-62a4112e1214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: /projects/sciences/computing/sheju347/.cache/huggingface\n",
      "HF_HUB_CACHE: /projects/sciences/computing/sheju347/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set env vars BEFORE importing huggingface modules\n",
    "os.environ[\"HF_HOME\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface/hub\"\n",
    "\n",
    "# Now import huggingface modules\n",
    "from huggingface_hub import constants\n",
    "\n",
    "print(\"HF_HOME:\", constants.HF_HOME)\n",
    "print(\"HF_HUB_CACHE:\", constants.HF_HUB_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a387e5-0079-41b2-9dfe-8e63dcc76d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainingData:\n",
    "    def __init__(self, context: str, question: str, is_correct: bool):\n",
    "        self.context = context\n",
    "        self.question = question\n",
    "        self.is_correct = is_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37146e82-d1ab-412d-9e56-f1606a6fb54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/sciences/computing/sheju347/miniconda3/envs/LLM311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/projects/sciences/computing/sheju347/miniconda3/envs/LLM311/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# model_name = \"google/flan-t5-large\"  # or t5-base, t5-large\n",
    "# model_name = \"google-t5/t5-base\"\n",
    "# model_name = \"google-t5/t5-small\"\n",
    "model_name = \"google-t5/t5-large\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/RAG/classifier/t5-large-epoch-10/checkpoint-94290\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944466f0-c394-429c-a47f-7d3fe074f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---training---\n",
      "6754\n",
      "Gastric cancer presenting as a krukenberg tumor at 22 weeks' gestation. Gastric cancer is rare during pregnancy, and often advanced upon presentation. A Krukenberg tumor presents a diagnostic and therapeutic challenge in the pregnant patient. We present a case of a 38-year-old woman at 22 weeks' gestation who presented with worsening epigastric pain, and was found to have a left pelvic mass on ultrasound, which was confirmed by magnetic resonance imaging. She went into active labor and delivered a viable infant via vaginal delivery. An exploratory laparotomy revealed a large mass originating from her left ovary and diffuse thickening of the lesser curvature of the stomach. Frozen section investigation revealed the presence of signet cell adenocarcinoma. Subsequent upper endoscopy showed linitis plastica, while biopsy confirmed the presence of adenocarcinoma. In conclusion, the occurrence of gastric cancer in pregnancy is rare despite extremely common symptoms. The management poses a challenge because of the need for early treatment, and the continuation of the pregnancy. False\n",
      "---test---\n",
      "910\n",
      "The tales of two neighbours: when cholecystitis does not preclude pancreatitis. An 83-year-old lady with no previous history of gallstones, presented with a sudden-onset severe epigastric pain radiating through to the back associated with nausea and vomiting. On examination, the patient's vital signs were normal. There was severe epigastric tenderness on palpation, as well as moderate right upper quadrant tenderness. Serological investigations showed raised inflammatory markers and serum lipase of 13 000, confirming the diagnosis of acute pancreatitis. Liver function tests were mildly deranged with a normal bilirubin of 12 Î¼mol/L. An abdominal ultrasound demonstrated a distended gallbladder with multiple subcentimeter gallstones and diffuse wall thickening up to 7 mm, consistent with cholecystitis. A follow-up CT abdomen demonstrated evidence of pancreatitis with moderate peripancreatic fat stranding. The diagnosis of concomitant acute cholecystitis and gallstone pancreatitis was made based on the radiological and biochemical findings. The patient underwent an uncomplicated laparoscopic cholecystectomy. The histopathology confirmed cholelithiasis with acute on chronic cholecystitis. True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "QUESTION_COUNT = 10178\n",
    "\n",
    "# log_file_list = [\n",
    "#     \"9-20-train_150_30_1st_H100.txt\", \n",
    "#     \"9-20-train_150_30_2nd_H100.txt\", \n",
    "#     \"9-21-train_150_30_3rd_H100.txt\",\n",
    "#     \"9-23-train_150_30_4th_H100.txt\",\n",
    "#     \"9-24-train_150_30_5th_H100.txt\",\n",
    "#                 ]\n",
    "# log_file = \"9-20-train_150_30_2nd_H100.txt\"\n",
    "training_file_list = [\"10-14-lora-context012-r16-epoch3-150-30-5-classifier-train.txt\"]\n",
    "test_file_list = [\"10-14-lora-context012-r16-epoch3-150-30-5-classifier-test.txt\"]\n",
    "\n",
    "# path = \"../../notebooks/\"\n",
    "path = \"./\"\n",
    "\n",
    "training_file_list = [path + log_file for log_file in training_file_list]\n",
    "test_file_list = [path + log_file for log_file in test_file_list]\n",
    "\n",
    "training_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "def get_data_list(file_name_list):\n",
    "    ret_data_list = []\n",
    "    for file_name in file_name_list:\n",
    "        with open(file_name) as f:\n",
    "            is_reading_context = False\n",
    "            context = \"\"\n",
    "        \n",
    "            is_reading_question = False\n",
    "            question = \"\"\n",
    "        \n",
    "            for line in f:\n",
    "                # if line == \"\\n\":\n",
    "                #     continue\n",
    "        \n",
    "                stripped_line = line.strip()\n",
    "                if stripped_line == \"Context:\":\n",
    "                    is_reading_context = True\n",
    "                elif stripped_line == \"Question:\":\n",
    "                    is_reading_context = False\n",
    "                    is_reading_question = True\n",
    "                elif stripped_line.startswith(\"[output]\"):\n",
    "                    is_correct = stripped_line[len(\"[output]\"):] == \"True\"\n",
    "                    context = context.strip()\n",
    "                    question = question.strip()\n",
    "                    data = TrainingData(context, question, is_correct)\n",
    "                    # print(\"aaa\", context, question, is_correct)\n",
    "        \n",
    "                    ret_data_list.append(data)\n",
    "        \n",
    "                    # if len(training_data_list) % 100 == 0:\n",
    "                    #     print(f\"finished processing {len(training_data_list)} data\")\n",
    "        \n",
    "                    # clear\n",
    "                    is_reading_context = False\n",
    "                    context = \"\"\n",
    "                    is_reading_question = False\n",
    "                    question = \"\"\n",
    "                    # break\n",
    "                else:\n",
    "                    if is_reading_context:\n",
    "                        context += line\n",
    "                    elif is_reading_question:\n",
    "                        question += line\n",
    "                        \n",
    "    return ret_data_list\n",
    "\n",
    "training_data_list = get_data_list(training_file_list)\n",
    "test_data_list = get_data_list(test_file_list)\n",
    "\n",
    "# training_data_list = training_data_list[:1000]\n",
    "print(\"---training---\")\n",
    "print(len(training_data_list))\n",
    "print(training_data_list[1].context, training_data_list[1].is_correct)\n",
    "print(\"---test---\")\n",
    "print(len(test_data_list))\n",
    "print(test_data_list[1].context, test_data_list[1].is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa5d205-a457-454e-93ed-7af70b86ec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_len 2332.0\n",
      "1493 1493\n"
     ]
    }
   ],
   "source": [
    "# Force training data to be balanced\n",
    "adapted_data_list = []\n",
    "incorrect_count = 0\n",
    "for data in training_data_list:\n",
    "    if data.is_correct == False:\n",
    "        incorrect_count += 1\n",
    "\n",
    "counter = 0\n",
    "for data in training_data_list:\n",
    "    if data.is_correct == False:\n",
    "        adapted_data_list.append(data)\n",
    "    else:\n",
    "        if counter < incorrect_count + 0:\n",
    "            adapted_data_list.append(data)\n",
    "            counter += 1\n",
    "\n",
    "training_data_list = adapted_data_list\n",
    "\n",
    "\n",
    "# Change the label based on length\n",
    "lengths = []\n",
    "for data in training_data_list:\n",
    "    lengths.append(len(data.context) + len(data.question))\n",
    "import statistics\n",
    "median_len = statistics.median(lengths)\n",
    "print(\"median_len\", median_len)\n",
    "\n",
    "# for data in training_data_list:\n",
    "#     if (len(data.context) + len(data.question)) > median_len:\n",
    "#         data.is_correct = True\n",
    "#     else:\n",
    "#         data.is_correct = False\n",
    "    \n",
    "\n",
    "false_count = 0\n",
    "true_count = 0\n",
    "for data in training_data_list:\n",
    "    if data.is_correct:\n",
    "        true_count += 1\n",
    "    else:\n",
    "        false_count += 1\n",
    "print(false_count, true_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4179036-f45c-4f78-a304-af7fe770b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./data/cfimdb-train.txt\"\n",
    "\n",
    "training_data_list = []\n",
    "\n",
    "with open(filename, 'r') as fp:\n",
    "    for line in fp:\n",
    "        label, org_sent = line.split(' ||| ')\n",
    "        # sent = org_sent.lower().strip()\n",
    "        # tokens = tokenizer.tokenize(\"[CLS] \" + sent + \" [SEP]\")\n",
    "        label = int(label.strip())\n",
    "        # if label not in num_labels:\n",
    "        #     num_labels[label] = len(num_labels)\n",
    "        data = TrainingData(org_sent, \"\", label)\n",
    "        training_data_list.append(data)\n",
    "\n",
    "print(training_data_list[6].context, training_data_list[6].is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "262fb3be-46cb-413a-af94-6263ad3fd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose training_data_list is your list of TrainingData objects\n",
    "training_dataframe = pd.DataFrame([{\n",
    "    \"context\": d.context,\n",
    "    \"question\": d.question,\n",
    "    \"label\": int(d.is_correct)   # True->1, False->0\n",
    "} for d in training_data_list])\n",
    "\n",
    "test_dataframe = pd.DataFrame([{\n",
    "    \"context\": d.context,\n",
    "    \"question\": d.question,\n",
    "    \"label\": int(d.is_correct)   # True->1, False->0\n",
    "} for d in test_data_list])\n",
    "\n",
    "# # Train/val/test split (e.g., 70/15/15)\n",
    "# train_df, temp_df = train_test_split(data, test_size=0.3, random_state=42, stratify=data[\"label\"])\n",
    "# val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n",
    "\n",
    "# print(len(train_df), len(val_df), len(test_df))\n",
    "# # print(test_df.iloc[0][\"context\"])\n",
    "# # print(test_df.iloc[0][\"question\"])\n",
    "# print(test_df.iloc[1][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9622e517-6e51-4ef2-b918-2084d49e3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "MAX_LEN = 1024 #512\n",
    "TARGET_MAX_LEN = 2\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=MAX_LEN, target_max_len=TARGET_MAX_LEN):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.target_max_len = target_max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = self.data.loc[idx, \"context\"]\n",
    "        question = self.data.loc[idx, \"question\"]\n",
    "        label = self.data.iloc[idx][\"label\"]\n",
    "\n",
    "        input_text = f\"question: {question} context: {context}\"\n",
    "        target_text = \"yes\" if label == 1 else \"no\"\n",
    "\n",
    "        # Keep return_tensors=None, let __getitem__ return 1D tensors\n",
    "        encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.target_max_len,\n",
    "            return_tensors=None\n",
    "        )\n",
    "\n",
    "        # Convert to tensors (1D)\n",
    "        input_ids = torch.tensor(encoding[\"input_ids\"], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(encoding[\"attention_mask\"], dtype=torch.long)\n",
    "        labels = torch.tensor(target_encoding[\"input_ids\"], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348b73ad-cb3b-41bd-ad2c-d05cde94d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = QADataset(train_df, tokenizer)\n",
    "# val_dataset = QADataset(val_df, tokenizer)\n",
    "# test_dataset = QADataset(test_df, tokenizer)\n",
    "\n",
    "train_dataset = QADataset(training_dataframe, tokenizer)\n",
    "test_dataset = QADataset(test_dataframe, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd059b2-9f45-4225-b8fa-003cfd40a0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[822, 10, 71, 5354, 7393, 18, 1490, 1871, 3977, 8247, 44, 706, 298, 17915, 5, 978, 2039, 4944, 24, 3, 88, 141, 3977, 163, 227, 255, 3, 9, 18423, 16, 8, 1379, 5, 465, 1137, 13, 1687, 47, 4187, 3, 390, 30, 8, 1510, 19819, 5, 4073, 13, 8, 826, 21059, 7, 228, 43, 19653, 8, 1687, 13, 8, 1871, 58, 784, 188, 908, 3, 10, 8422, 75, 53, 8, 9806, 16, 3, 9, 3, 7, 413, 630, 1102, 30, 3, 9, 1669, 8841, 298, 9182, 784, 279, 908, 3, 10, 3, 18536, 8, 9806, 2303, 11, 6011, 3, 9, 306, 562, 2912, 784, 254, 908, 3, 10, 8566, 13, 3, 9, 1407, 12, 1961, 8, 9182, 1102, 784, 308, 908, 3, 10, 15856, 53, 3, 5379, 7903, 169, 383, 2085, 2625, 10, 71, 495, 13, 12914, 9806, 1687, 788, 12, 3, 9, 2329, 16643, 3, 7, 291, 287, 9, 5, 37, 495, 2196, 270, 77, 3315, 8, 7544, 1687, 13, 3, 9, 5354, 7393, 18, 1490, 3955, 21118, 113, 8247, 11612, 26, 16, 160, 2039, 31, 7, 6026, 11, 47, 3654, 30, 6870, 44, 8, 2833, 5, 37, 3739, 27771, 13, 8, 1871, 11, 160, 1362, 130, 2841, 21, 3976, 42, 3957, 13, 7095, 6, 237, 273, 13, 16712, 5233, 5, 7053, 6, 150, 3739, 3179, 13, 3, 9, 2071, 7925, 2637, 47, 4466, 57, 18325, 7137, 227, 8, 3879, 552, 8, 336, 3583, 3938, 5, 37, 1510, 19819, 19678, 3866, 11, 3224, 3957, 13, 4756, 68, 5111, 3, 9, 508, 2329, 16643, 8985, 3, 14739, 45, 8, 339, 1481, 13, 8, 646, 9370, 2234, 109, 6, 84, 141, 3536, 24281, 26, 8, 842, 3, 5885, 181, 4900, 9522, 20, 14678, 5, 978, 17, 4478, 6498, 3217, 3, 9, 731, 18, 6801, 3, 7, 291, 287, 9, 24, 1551, 16, 8027, 17, 4094, 8, 82, 32, 16464, 138, 6316, 5, 37, 2071, 32, 21715, 13, 48, 12914, 9806, 1687, 47, 442, 83, 920, 38, 271, 3, 15942, 12, 3, 9, 12699, 3, 31695, 25427, 1092, 257, 3334, 28, 3, 9, 8985, 18, 3897, 28219, 16216, 2258, 23599, 3, 32, 115, 7593, 53, 646, 3, 31695, 14, 53, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[9][\"input_ids\"].tolist())\n",
    "# print(len(train_dataset[2][\"input_ids\"].tolist()))\n",
    "# print(train_dataset[1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bc2616a-d027-4986-8215-3a39d64c774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2593613/1349905499.py:60: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "output_dir = \"/projects/sciences/computing/sheju347/RAG/classifier/10-19-t5-large-epoch-10\" # \"./results\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     from sklearn.metrics import accuracy_score, f1_score\n",
    "#     logits, labels = eval_pred\n",
    "#     preds = logits.argmax(-1)\n",
    "#     return {\n",
    "#         \"accuracy\": accuracy_score(labels, preds),\n",
    "#         \"f1\": f1_score(labels, preds)\n",
    "#     }\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    import torch\n",
    "\n",
    "    # Extract logits and labels\n",
    "    logits = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # If logits is a tuple (common for seq2seq models), take the first element\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # Convert logits to predicted token IDs\n",
    "    pred_ids = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    \n",
    "    # Decode to text\n",
    "    decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Map yes/no to 1/0\n",
    "    y_pred = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_preds]\n",
    "    \n",
    "    # True labels\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    y_true = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_labels]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6daf404-ecf4-44d3-a3c9-8a368a88ac97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16424' max='29860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16424/29860 1:13:41 < 1:00:17, 3.71 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.970250</td>\n",
       "      <td>0.437363</td>\n",
       "      <td>0.493069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>2.725734</td>\n",
       "      <td>0.352747</td>\n",
       "      <td>0.320646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>1.591802</td>\n",
       "      <td>0.409890</td>\n",
       "      <td>0.461384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.716623</td>\n",
       "      <td>0.380220</td>\n",
       "      <td>0.423313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>2.293863</td>\n",
       "      <td>0.343956</td>\n",
       "      <td>0.298472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.152400</td>\n",
       "      <td>2.081471</td>\n",
       "      <td>0.363736</td>\n",
       "      <td>0.364435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>1.632737</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.548446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>1.836248</td>\n",
       "      <td>0.424176</td>\n",
       "      <td>0.488281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>2.111387</td>\n",
       "      <td>0.383516</td>\n",
       "      <td>0.403826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>2.384259</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.450704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 16/455 00:01 < 00:33, 13.11 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35700d5c-db2e-4319-a4a1-b3a8e7acd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "# model_name = \"google-bert/bert-base-uncased\"\n",
    "# model_name = \"allenai/longformer-base-4096\"\n",
    "model_name = \"/projects/sciences/computing/sheju347/RAG/classifier/10-19-t5-large-epoch-10/checkpoint-29860\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eee8ea-d6c1-46fc-9329-b5f7cefc4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = trainer.predict(test_dataset)\n",
    "print(preds.metrics)  # optional, shows overall metrics\n",
    "\n",
    "# Get logits\n",
    "logits = preds.predictions  # <--- use .predictions\n",
    "\n",
    "\n",
    "# If logits is a tuple (common for seq2seq models), take the first element\n",
    "if isinstance(logits, tuple):\n",
    "    logits = logits[0]  # shape: (num_examples, seq_len, vocab_size)\n",
    "\n",
    "print(\"logits\", logits)\n",
    "# Convert logits to token IDs\n",
    "pred_ids = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "\n",
    "print (\"pred_ids\", pred_ids)\n",
    "# Decode token IDs to text\n",
    "decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer.batch_decode(preds.label_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"decoded_preds\", decoded_preds)\n",
    "print(\"decoded_labels\", decoded_labels)\n",
    "\n",
    "# Convert yes/no to 1/0\n",
    "y_pred = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_preds]\n",
    "y_true = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_labels]\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a48550-f979-4c48-a338-e137073a3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# trainer.args.predict_with_generate = False  # make sure no .generate()\n",
    "\n",
    "chunk_size = 500  # adjust depending on your GPU memory\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "\n",
    "for start in range(0, len(test_dataset), chunk_size):\n",
    "    end = min(start + chunk_size, len(test_dataset))\n",
    "    subset = Subset(test_dataset, range(start, end))\n",
    "    preds = trainer.predict(subset)\n",
    "\n",
    "    logits = preds.predictions\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    all_logits.append(logits)\n",
    "    all_labels.append(preds.label_ids)\n",
    "\n",
    "# Concatenate all chunks\n",
    "logits = np.concatenate(all_logits, axis=0)\n",
    "labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(\"logits shape:\", logits.shape)\n",
    "\n",
    "# Convert logits to predicted token IDs\n",
    "pred_ids = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "\n",
    "# Only take the first token for yes/no classification\n",
    "first_token_ids = pred_ids[:, 0]\n",
    "\n",
    "# Decode predictions and labels\n",
    "decoded_preds = tokenizer.batch_decode(first_token_ids, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(\"decoded_preds sample:\", decoded_preds[:20])\n",
    "print(\"decoded_labels sample:\", decoded_labels[:20])\n",
    "\n",
    "# Map yes/no to 1/0\n",
    "y_pred = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_preds]\n",
    "y_true = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_labels]\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9357a5-391c-466f-bed7-517daf0588d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(test_dataset)\n",
    "print(preds)\n",
    "y_pred = preds.predictions.argmax(-1)\n",
    "y_true = preds.label_ids\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4f2d9-1a80-4d0d-aa99-c9778e7b6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = preds.predictions.argmax(-1)\n",
    "count_predict_1 = 0\n",
    "count_label_1 = 0\n",
    "for i in range(len(test_dataset)):\n",
    "    if i < 20:\n",
    "        print(sum(test_dataset[i][\"attention_mask\"]), test_dataset[i][\"labels\"], y_preds[i])\n",
    "    count_predict_1 += y_preds[i]\n",
    "    count_label_1 += test_dataset[i][\"labels\"].item()\n",
    "\n",
    "print(count_predict_1, \"/\", len(test_dataset), count_predict_1 / len(test_dataset))\n",
    "print(count_label_1, \"/\", len(test_dataset), count_label_1 / len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6108352-60d6-41fb-ad7e-5a3b09584162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM311)",
   "language": "python",
   "name": "llm311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a855791-aa19-49dd-ac5d-62a4112e1214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: /projects/sciences/computing/sheju347/.cache/huggingface\n",
      "HF_HUB_CACHE: /projects/sciences/computing/sheju347/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set env vars BEFORE importing huggingface modules\n",
    "os.environ[\"HF_HOME\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface/hub\"\n",
    "\n",
    "# Now import huggingface modules\n",
    "from huggingface_hub import constants\n",
    "\n",
    "print(\"HF_HOME:\", constants.HF_HOME)\n",
    "print(\"HF_HUB_CACHE:\", constants.HF_HUB_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b8a852-774d-4bc3-9f84-84429f350612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainingData:\n",
    "    def __init__(self, context: str, question: str, is_correct: bool):\n",
    "        self.context = context\n",
    "        self.question = question\n",
    "        self.is_correct = is_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03fef2c-dbf9-47ec-938f-e59e4f9a2b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/sciences/computing/sheju347/miniconda3/envs/LLM311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/projects/sciences/computing/sheju347/miniconda3/envs/LLM311/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "model_name = \"google-bert/bert-base-uncased\"\n",
    "# model_name = \"allenai/longformer-base-4096\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944466f0-c394-429c-a47f-7d3fe074f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "QUESTION_COUNT = 10178\n",
    "\n",
    "# log_file = \"9-20-train_150_30_1st_H100.txt\"\n",
    "log_file = \"9-20-train_150_30_2nd_H100.txt\"\n",
    "\n",
    "path = \"../../notebooks/\"\n",
    "\n",
    "file_name = path + log_file\n",
    "\n",
    "training_data_list = []\n",
    "\n",
    "with open(file_name) as f:\n",
    "    is_reading_context = False\n",
    "    context = \"\"\n",
    "\n",
    "    is_reading_question = False\n",
    "    question = \"\"\n",
    "\n",
    "    for line in f:\n",
    "        # if line == \"\\n\":\n",
    "        #     continue\n",
    "\n",
    "        stripped_line = line.strip()\n",
    "        if stripped_line == \"Context:\":\n",
    "            is_reading_context = True\n",
    "        elif stripped_line == \"Question:\":\n",
    "            is_reading_context = False\n",
    "            is_reading_question = True\n",
    "        elif stripped_line.startswith(\"[output]\"):\n",
    "            is_correct = stripped_line[len(\"[output]\"):] == \"True\"\n",
    "            context = context.strip()\n",
    "            question = question.strip()\n",
    "            data = TrainingData(context, question, is_correct)\n",
    "            # print(\"aaa\", context, question, is_correct)\n",
    "\n",
    "            training_data_list.append(data)\n",
    "\n",
    "            # if len(training_data_list) % 100 == 0:\n",
    "            #     print(f\"finished processing {len(training_data_list)} data\")\n",
    "\n",
    "            # clear\n",
    "            is_reading_context = False\n",
    "            context = \"\"\n",
    "            is_reading_question = False\n",
    "            question = \"\"\n",
    "            # break\n",
    "        else:\n",
    "            if is_reading_context:\n",
    "                context += line\n",
    "            elif is_reading_question:\n",
    "                question += line\n",
    "\n",
    "print(len(training_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7311932d-78fc-4bed-af9e-ddd9aece04ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\" I never actually thought that a film could be so great , but alas I was wrong . Great acting , great plot , fun effects . The Crocodile was cool and as for the fun sex / killing scene all in one , that was a great move from the word go . It was truly shocking and that is a compliment ! How can someone make this film , watch it back and then actually say \"\" \"\" Yeah , my favorite movie . People will watch that \"\" \"\" If you have n't seen it I beg you watch it . \"\"\"\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "filename = \"./data/cfimdb-train.txt\"\n",
    "\n",
    "training_data_list = []\n",
    "\n",
    "with open(filename, 'r') as fp:\n",
    "    for line in fp:\n",
    "        label, org_sent = line.split(' ||| ')\n",
    "        # sent = org_sent.lower().strip()\n",
    "        # tokens = tokenizer.tokenize(\"[CLS] \" + sent + \" [SEP]\")\n",
    "        label = int(label.strip())\n",
    "        # if label not in num_labels:\n",
    "        #     num_labels[label] = len(num_labels)\n",
    "        data = TrainingData(org_sent, \"\", label)\n",
    "        training_data_list.append(data)\n",
    "\n",
    "print(training_data_list[6].context, training_data_list[6].is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262fb3be-46cb-413a-af94-6263ad3fd066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1194 256 257\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose training_data_list is your list of TrainingData objects\n",
    "data = pd.DataFrame([{\n",
    "    \"context\": d.context,\n",
    "    \"question\": d.question,\n",
    "    \"label\": int(d.is_correct)   # True->1, False->0\n",
    "} for d in training_data_list])\n",
    "\n",
    "# Train/val/test split (e.g., 70/15/15)\n",
    "train_df, temp_df = train_test_split(data, test_size=0.3, random_state=42, stratify=data[\"label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "# print(test_df.iloc[0][\"context\"])\n",
    "# print(test_df.iloc[0][\"question\"])\n",
    "print(test_df.iloc[1][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9622e517-6e51-4ef2-b918-2084d49e3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=512):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = self.data.loc[idx, \"context\"]\n",
    "        question = self.data.loc[idx, \"question\"]\n",
    "        label = self.data.loc[idx, \"label\"]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            context,\n",
    "            #question,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348b73ad-cb3b-41bd-ad2c-d05cde94d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QADataset(train_df, tokenizer)\n",
    "val_dataset = QADataset(val_df, tokenizer)\n",
    "test_dataset = QADataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd059b2-9f45-4225-b8fa-003cfd40a0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2013, 2054, 1045, 1005, 2310, 3191, 1037, 2843, 1997, 2111, 2020, 9364, 2011, 2023, 2143, 1010, 4102, 2000, 2112, 1015, 1012, 3322, 1045, 2071, 1050, 1005, 1056, 3305, 2023, 2021, 2044, 1037, 2978, 1997, 2245, 1045, 2228, 2027, 2024, 2157, 2000, 2022, 1012, 2061, 4063, 4059, 2232, 4247, 2010, 2755, 2241, 4129, 1997, 18178, 1005, 1055, 2166, 2008, 2002, 2318, 1999, 2112, 1015, 1012, 2112, 1015, 2409, 1037, 2466, 1997, 1037, 4329, 3048, 2013, 4895, 25013, 16508, 2000, 2019, 4821, 3144, 7091, 1012, 2112, 1016, 4136, 1037, 2466, 1997, 1037, 4329, 2008, 5829, 2013, 4895, 25013, 16508, 2000, 1037, 3294, 7736, 7091, 1012, 2009, 2003, 2025, 2061, 4063, 4059, 2232, 1005, 1055, 6346, 2008, 2122, 1016, 3033, 1997, 18178, 1005, 1055, 2166, 2018, 3294, 2367, 13105, 1012, 2002, 29116, 15867, 2000, 2425, 2119, 1999, 1037, 7199, 19647, 2126, 1012, 1996, 13972, 2089, 2514, 1037, 2843, 2488, 2746, 2041, 1997, 1996, 5988, 2044, 2112, 1015, 2084, 2112, 1016, 2021, 2008, 2003, 1996, 4507, 1997, 18178, 1005, 1055, 2166, 1998, 1999, 2026, 5448, 2036, 1996, 6346, 1997, 1996, 2472, 1012, 1996, 2143, 2003, 2521, 2013, 3819, 1012, 2009, 2003, 2205, 2146, 1012, 2012, 2560, 1999, 2112, 1015, 2057, 2387, 2367, 5919, 1997, 1996, 2162, 2004, 1996, 26955, 2018, 14152, 1012, 1999, 2112, 1016, 2027, 6187, 1050, 1005, 1056, 4608, 1037, 3338, 1998, 2057, 2156, 2037, 3616, 7887, 2108, 4359, 2011, 2331, 1998, 5425, 1012, 18178, 1005, 1055, 5425, 1998, 2331, 2024, 9411, 2007, 6649, 1012, 1996, 2143, 2003, 6551, 25596, 3762, 1996, 7982, 2108, 1999, 3009, 1012, 3841, 27113, 3972, 23790, 2003, 6659, 2004, 1996, 23916, 23157, 15830, 1012, 2061, 2065, 2017, 1005, 2310, 2464, 2112, 1015, 2017, 2097, 2156, 1037, 2172, 4788, 4129, 1997, 1037, 2200, 2367, 2466, 1999, 2112, 1016, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[1][\"input_ids\"].tolist())\n",
    "# print(train_dataset[1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc2616a-d027-4986-8215-3a39d64c774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403628/1465478003.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6daf404-ecf4-44d3-a3c9-8a368a88ac97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1791' max='1791' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1791/1791 01:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.209577</td>\n",
       "      <td>0.957031</td>\n",
       "      <td>0.957529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.244038</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.273410</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.961240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1791, training_loss=0.14060368756220235, metrics={'train_runtime': 87.2137, 'train_samples_per_second': 41.072, 'train_steps_per_second': 20.536, 'total_flos': 942463800299520.0, 'train_loss': 0.14060368756220235, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35700d5c-db2e-4319-a4a1-b3a8e7acd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "# model_name = \"google-bert/bert-base-uncased\"\n",
    "# model_name = \"allenai/longformer-base-4096\"\n",
    "model_name = \"./results/checkpoint-3562\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff9357a5-391c-466f-bed7-517daf0588d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-4.0941863 ,  4.026944  ],\n",
      "       [-4.136982  ,  4.05463   ],\n",
      "       [-4.0876756 ,  4.017905  ],\n",
      "       [-4.1084943 ,  3.9993894 ],\n",
      "       [-4.129156  ,  4.0948544 ],\n",
      "       [ 4.521436  , -4.6694183 ],\n",
      "       [-4.136835  ,  4.047822  ],\n",
      "       [ 4.548204  , -4.7400475 ],\n",
      "       [-4.092423  ,  4.0306506 ],\n",
      "       [-4.025205  ,  3.9671757 ],\n",
      "       [ 4.5302463 , -4.7546487 ],\n",
      "       [ 4.509764  , -4.6941876 ],\n",
      "       [-4.0689826 ,  4.035645  ],\n",
      "       [-4.0128574 ,  3.8946562 ],\n",
      "       [-4.0726314 ,  3.956131  ],\n",
      "       [ 4.5017285 , -4.6144614 ],\n",
      "       [ 4.509204  , -4.67687   ],\n",
      "       [-4.141014  ,  4.02516   ],\n",
      "       [-0.2300345 ,  0.33628598],\n",
      "       [-4.0313773 ,  3.9832835 ],\n",
      "       [ 4.5410514 , -4.653341  ],\n",
      "       [ 4.4994125 , -4.5782127 ],\n",
      "       [-4.1176777 ,  4.0297937 ],\n",
      "       [-4.106482  ,  4.041486  ],\n",
      "       [ 4.5662856 , -4.6570344 ],\n",
      "       [ 4.497233  , -4.7210975 ],\n",
      "       [-4.1407313 ,  4.0535064 ],\n",
      "       [-4.035175  ,  3.9575922 ],\n",
      "       [ 4.556559  , -4.6414084 ],\n",
      "       [ 4.5749574 , -4.7112927 ],\n",
      "       [-4.135611  ,  4.01923   ],\n",
      "       [-4.153253  ,  4.051211  ],\n",
      "       [ 4.560682  , -4.7598243 ],\n",
      "       [ 4.444158  , -4.6635    ],\n",
      "       [-3.952436  ,  3.906622  ],\n",
      "       [-4.0415154 ,  3.9516072 ],\n",
      "       [-4.068433  ,  3.9924247 ],\n",
      "       [-4.1363034 ,  4.049211  ],\n",
      "       [ 2.8233595 , -2.8138373 ],\n",
      "       [-4.130011  ,  4.042032  ],\n",
      "       [-4.112265  ,  4.0611935 ],\n",
      "       [ 4.5515375 , -4.7055326 ],\n",
      "       [ 4.56053   , -4.7513576 ],\n",
      "       [ 4.474551  , -4.5084343 ],\n",
      "       [-4.1414337 ,  4.036814  ],\n",
      "       [-4.1342297 ,  4.031447  ],\n",
      "       [ 4.5166154 , -4.727121  ],\n",
      "       [ 4.563042  , -4.7527223 ],\n",
      "       [ 4.550449  , -4.701347  ],\n",
      "       [ 4.422027  , -4.558803  ],\n",
      "       [-4.102095  ,  3.9951813 ],\n",
      "       [-4.070628  ,  4.029774  ],\n",
      "       [ 4.499463  , -4.6763597 ],\n",
      "       [ 4.538545  , -4.74362   ],\n",
      "       [ 4.3608775 , -4.463118  ],\n",
      "       [ 4.4552145 , -4.5788503 ],\n",
      "       [ 4.5805764 , -4.7249265 ],\n",
      "       [-4.103514  ,  4.0580525 ],\n",
      "       [-4.0497346 ,  3.9442449 ],\n",
      "       [ 4.4904623 , -4.7563467 ],\n",
      "       [ 4.515633  , -4.5337567 ],\n",
      "       [-4.0406694 ,  3.9839694 ],\n",
      "       [-4.1404715 ,  4.0305624 ],\n",
      "       [-4.0790925 ,  4.0151863 ],\n",
      "       [-4.116357  ,  4.0789933 ],\n",
      "       [-3.9697266 ,  3.8889246 ],\n",
      "       [ 4.4813232 , -4.5500402 ],\n",
      "       [-4.052597  ,  3.9982438 ],\n",
      "       [ 4.5417852 , -4.730944  ],\n",
      "       [-4.1295834 ,  4.0879745 ],\n",
      "       [ 4.4890065 , -4.6748495 ],\n",
      "       [ 4.55207   , -4.7293444 ],\n",
      "       [ 4.4002614 , -4.464856  ],\n",
      "       [-4.1144404 ,  4.0734625 ],\n",
      "       [ 4.590628  , -4.7134027 ],\n",
      "       [ 4.4549813 , -4.673855  ],\n",
      "       [ 4.394499  , -4.4730735 ],\n",
      "       [-4.095536  ,  4.0232387 ],\n",
      "       [-4.103879  ,  4.0202055 ],\n",
      "       [ 4.5467176 , -4.7446656 ],\n",
      "       [ 4.530153  , -4.6622844 ],\n",
      "       [ 4.557072  , -4.715564  ],\n",
      "       [ 4.55801   , -4.755628  ],\n",
      "       [-4.1253953 ,  4.0668635 ],\n",
      "       [-4.1027126 ,  4.0634313 ],\n",
      "       [ 4.4544554 , -4.456525  ],\n",
      "       [-3.6768093 ,  3.5155787 ],\n",
      "       [-4.074293  ,  3.9659016 ],\n",
      "       [ 3.7810466 , -3.8509214 ],\n",
      "       [ 4.555505  , -4.722389  ],\n",
      "       [-4.046774  ,  3.879705  ],\n",
      "       [-4.121431  ,  3.984484  ],\n",
      "       [-4.1270733 ,  4.08729   ],\n",
      "       [-4.108185  ,  4.05087   ],\n",
      "       [-4.1203794 ,  4.025751  ],\n",
      "       [ 4.5654454 , -4.712179  ],\n",
      "       [ 4.550001  , -4.730496  ],\n",
      "       [ 4.552956  , -4.752677  ],\n",
      "       [-4.0999737 ,  4.0207977 ],\n",
      "       [-4.110126  ,  4.0571637 ],\n",
      "       [ 4.543001  , -4.751565  ],\n",
      "       [-4.045007  ,  3.9350245 ],\n",
      "       [-4.0339394 ,  3.9582858 ],\n",
      "       [ 4.5435915 , -4.676995  ],\n",
      "       [ 4.5565085 , -4.7344646 ],\n",
      "       [ 4.5578012 , -4.752319  ],\n",
      "       [-4.124986  ,  4.059322  ],\n",
      "       [-3.9639525 ,  3.867461  ],\n",
      "       [ 4.4987206 , -4.610922  ],\n",
      "       [ 4.523207  , -4.716174  ],\n",
      "       [-4.13792   ,  4.057469  ],\n",
      "       [ 4.4891906 , -4.707114  ],\n",
      "       [ 4.5722437 , -4.7254457 ],\n",
      "       [-4.123422  ,  4.03652   ],\n",
      "       [ 4.4935565 , -4.5541987 ],\n",
      "       [ 4.411279  , -4.483984  ],\n",
      "       [-3.7150233 ,  3.5797398 ],\n",
      "       [-4.1397257 ,  4.056473  ],\n",
      "       [-4.122399  ,  4.074991  ],\n",
      "       [-4.096836  ,  4.0476503 ],\n",
      "       [ 4.5605536 , -4.675712  ],\n",
      "       [-4.1215553 ,  4.0385065 ],\n",
      "       [-3.4729714 ,  3.3006268 ],\n",
      "       [-4.116589  ,  4.069344  ],\n",
      "       [ 4.562938  , -4.7455583 ],\n",
      "       [ 0.0553887 , -0.12915625],\n",
      "       [-4.04803   ,  3.9359412 ],\n",
      "       [-4.1538844 ,  4.0395446 ],\n",
      "       [ 4.552895  , -4.7307053 ],\n",
      "       [ 4.512941  , -4.710599  ],\n",
      "       [ 4.538966  , -4.7505555 ],\n",
      "       [ 4.469134  , -4.596425  ],\n",
      "       [ 4.499148  , -4.544673  ],\n",
      "       [ 4.5155845 , -4.743428  ],\n",
      "       [-3.704638  ,  3.6864245 ],\n",
      "       [ 4.5003123 , -4.543634  ],\n",
      "       [ 4.538197  , -4.73174   ],\n",
      "       [ 4.534416  , -4.728063  ],\n",
      "       [-4.128192  ,  4.0495725 ],\n",
      "       [-4.1053977 ,  4.050987  ],\n",
      "       [ 4.5697775 , -4.727422  ],\n",
      "       [ 4.525091  , -4.632059  ],\n",
      "       [-4.1290317 ,  4.066597  ],\n",
      "       [-4.1115017 ,  4.0602446 ],\n",
      "       [-1.7565894 ,  1.7024451 ],\n",
      "       [ 4.5493064 , -4.715786  ],\n",
      "       [ 4.489562  , -4.628849  ],\n",
      "       [-3.9426007 ,  3.8667827 ],\n",
      "       [-4.131184  ,  3.992916  ],\n",
      "       [ 4.56037   , -4.75086   ],\n",
      "       [ 4.5015197 , -4.5989666 ],\n",
      "       [-4.116328  ,  4.0434346 ],\n",
      "       [-4.075067  ,  4.0006495 ],\n",
      "       [ 4.460724  , -4.515066  ],\n",
      "       [ 4.524529  , -4.7285557 ],\n",
      "       [ 4.5377164 , -4.743289  ],\n",
      "       [-4.0913386 ,  4.043039  ],\n",
      "       [ 2.7029042 , -2.7143655 ],\n",
      "       [ 4.5065937 , -4.6355467 ],\n",
      "       [-3.9839785 ,  3.8520122 ],\n",
      "       [ 4.489647  , -4.710043  ],\n",
      "       [-4.099293  ,  3.9912448 ],\n",
      "       [ 4.5327263 , -4.6871195 ],\n",
      "       [-4.0594273 ,  3.9739025 ],\n",
      "       [-4.0649376 ,  3.950991  ],\n",
      "       [-3.2141263 ,  3.125252  ],\n",
      "       [ 4.497898  , -4.613262  ],\n",
      "       [-4.123581  ,  4.0457196 ],\n",
      "       [ 2.7247856 , -2.82271   ],\n",
      "       [ 4.4428754 , -4.5306287 ],\n",
      "       [ 4.539153  , -4.760145  ],\n",
      "       [ 4.5159173 , -4.659744  ],\n",
      "       [-4.1105046 ,  4.0332646 ],\n",
      "       [ 4.534925  , -4.6936584 ],\n",
      "       [-4.0980916 ,  3.9790845 ],\n",
      "       [-0.14092267, -0.40479925],\n",
      "       [ 4.549573  , -4.740762  ],\n",
      "       [ 4.4631805 , -4.5152845 ],\n",
      "       [ 4.585721  , -4.7416697 ],\n",
      "       [-4.044034  ,  3.979796  ],\n",
      "       [-3.5088427 ,  3.3192313 ],\n",
      "       [-4.031829  ,  4.0507073 ],\n",
      "       [ 4.560492  , -4.7284617 ],\n",
      "       [-4.077388  ,  3.9922562 ],\n",
      "       [ 4.5447407 , -4.748812  ],\n",
      "       [-4.092207  ,  4.014596  ],\n",
      "       [ 4.5592666 , -4.7697396 ],\n",
      "       [-4.1005597 ,  4.036263  ],\n",
      "       [-2.4140196 ,  2.1908557 ],\n",
      "       [-4.1324415 ,  4.012795  ],\n",
      "       [ 4.5536203 , -4.685997  ],\n",
      "       [-4.1006055 ,  4.048124  ],\n",
      "       [-4.058764  ,  3.9856076 ],\n",
      "       [ 4.3704867 , -4.379099  ],\n",
      "       [ 4.500023  , -4.6380854 ],\n",
      "       [ 4.5807524 , -4.718157  ],\n",
      "       [ 4.538414  , -4.74406   ],\n",
      "       [ 4.5735445 , -4.7011385 ],\n",
      "       [ 1.1648556 , -1.1594597 ],\n",
      "       [ 4.46236   , -4.6959386 ],\n",
      "       [-4.156628  ,  4.0615125 ],\n",
      "       [-4.08871   ,  3.999948  ],\n",
      "       [ 4.5488296 , -4.7261343 ],\n",
      "       [-4.1321034 ,  4.027938  ],\n",
      "       [ 4.5124245 , -4.6989775 ],\n",
      "       [ 4.550338  , -4.6762605 ],\n",
      "       [-4.1298485 ,  4.064367  ],\n",
      "       [-4.1106343 ,  4.0302095 ],\n",
      "       [-4.0748916 ,  4.0080004 ],\n",
      "       [-4.119232  ,  3.9929059 ],\n",
      "       [ 4.5056896 , -4.7429795 ],\n",
      "       [ 4.489932  , -4.6391015 ],\n",
      "       [-4.1314554 ,  4.0436177 ],\n",
      "       [ 4.4198174 , -4.488879  ],\n",
      "       [-4.071485  ,  3.9881947 ],\n",
      "       [ 4.5531116 , -4.6480665 ],\n",
      "       [-4.022632  ,  3.9809437 ],\n",
      "       [ 4.555165  , -4.693361  ],\n",
      "       [ 4.5267725 , -4.7375035 ],\n",
      "       [ 4.528596  , -4.678162  ],\n",
      "       [-4.1382637 ,  4.038887  ],\n",
      "       [ 4.518231  , -4.667399  ],\n",
      "       [-3.0545523 ,  2.9204867 ],\n",
      "       [-4.073877  ,  4.0310135 ],\n",
      "       [-4.129264  ,  4.045621  ],\n",
      "       [ 4.5533075 , -4.7495084 ],\n",
      "       [ 4.550072  , -4.743504  ],\n",
      "       [-4.08376   ,  4.0105424 ],\n",
      "       [-1.8437562 ,  1.751936  ],\n",
      "       [ 4.552247  , -4.746509  ],\n",
      "       [ 4.5236387 , -4.677014  ],\n",
      "       [ 4.55292   , -4.759438  ],\n",
      "       [-4.0700254 ,  3.9558015 ],\n",
      "       [-4.09207   ,  4.038442  ],\n",
      "       [ 4.548027  , -4.707371  ],\n",
      "       [-4.11675   ,  4.0588956 ],\n",
      "       [-4.14306   ,  4.0528216 ],\n",
      "       [ 4.504252  , -4.6245704 ],\n",
      "       [ 4.49688   , -4.5890665 ],\n",
      "       [ 4.4120274 , -4.6587987 ],\n",
      "       [-4.067782  ,  4.007255  ],\n",
      "       [ 4.5284357 , -4.7479663 ],\n",
      "       [ 4.4641643 , -4.577504  ],\n",
      "       [-4.070234  ,  4.0251937 ],\n",
      "       [ 4.565767  , -4.7344832 ],\n",
      "       [-4.080506  ,  4.025191  ],\n",
      "       [-4.1372533 ,  4.075564  ],\n",
      "       [-4.10639   ,  4.004724  ],\n",
      "       [ 4.561042  , -4.707213  ],\n",
      "       [-4.0471897 ,  3.908387  ],\n",
      "       [ 4.4893384 , -4.5303044 ],\n",
      "       [-4.0576468 ,  3.940625  ],\n",
      "       [ 4.3527803 , -4.5101714 ],\n",
      "       [ 4.5206685 , -4.726084  ],\n",
      "       [-4.104826  ,  3.9931605 ],\n",
      "       [ 4.499018  , -4.7201166 ],\n",
      "       [-4.0874734 ,  3.9779673 ]], dtype=float32), label_ids=array([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1]), metrics={'test_loss': 0.0529036745429039, 'test_accuracy': 0.9844357976653697, 'test_f1': 0.984251968503937, 'test_runtime': 1.3527, 'test_samples_per_second': 189.996, 'test_steps_per_second': 95.368})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       129\n",
      "           1       0.99      0.98      0.98       128\n",
      "\n",
      "    accuracy                           0.98       257\n",
      "   macro avg       0.98      0.98      0.98       257\n",
      "weighted avg       0.98      0.98      0.98       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(test_dataset)\n",
    "print(preds)\n",
    "y_pred = preds.predictions.argmax(-1)\n",
    "y_true = preds.label_ids\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4f2d9-1a80-4d0d-aa99-c9778e7b6f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM311)",
   "language": "python",
   "name": "llm311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

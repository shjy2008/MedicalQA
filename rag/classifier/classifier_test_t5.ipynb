{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dad334b-c3bf-4f10-84f2-8dbbf11adb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: /projects/sciences/computing/sheju347/.cache/huggingface\n",
      "HF_HUB_CACHE: /projects/sciences/computing/sheju347/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set env vars BEFORE importing huggingface modules\n",
    "os.environ[\"HF_HOME\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface/hub\"\n",
    "\n",
    "# Now import huggingface modules\n",
    "from huggingface_hub import constants\n",
    "\n",
    "print(\"HF_HOME:\", constants.HF_HOME)\n",
    "print(\"HF_HUB_CACHE:\", constants.HF_HUB_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb50b46-c7ea-4f26-8c94-b0073a148fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainingData:\n",
    "    def __init__(self, context: str, question: str, is_correct: bool):\n",
    "        self.context = context\n",
    "        self.question = question\n",
    "        self.is_correct = is_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc392bcf-e20d-40ca-bc71-782ba288ef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# model_name = \"google/flan-t5-large\"  # or t5-base, t5-large\n",
    "# model_name = \"google-t5/t5-base\"\n",
    "# model_name = \"google-t5/t5-small\"\n",
    "# model_name = \"google-t5/t5-large\"\n",
    "model_name = \"/projects/sciences/computing/sheju347/RAG/classifier/t5-large-epoch-10/checkpoint-94290\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/RAG/classifier/t5-large-epoch-30/checkpoint-94290\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/RAG/classifier/t5-large-epoch-30/checkpoint-188580\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96747167-1518-466c-912d-1d91f1f728b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6365\n",
      "A cost-effective junior resident training and assessment simulator for orthopaedic surgical skills via fundamentals of orthopaedic surgery: AAOS exhibit selection. Psychomotor testing has been recently incorporated into residency training programs not only to objectively assess a surgeon's abilities but also to address current patient-safety advocacy and medicolegal trends. The purpose of this study was to develop and test a cost-effective psychomotor training and assessment tool-The Fundamentals of Orthopaedic Surgery (FORS)-for junior-level orthopaedic surgery resident education. An orthopaedic skills board was made from supplies purchased at a local hardware store with a total cost of less than $350 so as to assess six different psychomotor skills. The six skills included fracture reduction, three-dimensional drill accuracy, simulated fluoroscopy-guided drill accuracy, depth-of-plunge minimization, drill-by-feel accuracy, and suture speed and quality. Medical students, residents, and attending physicians from three orthopaedic surgery residency programs accredited by the Accreditation Council for Graduate Medical Education participated in the study. Twenty-five medical students were retained for longitudinal training and testing for four weeks. Each training session involved an initial examination followed by thirty minutes of board training. The time to perform each task was measured with accuracy measurements for the appropriate tasks. Statistical analysis was done with one-way analysis of variance, with significance set at p &lt; 0.05. Forty-seven medical students, twenty-nine attending physicians, and fifty-eight orthopaedic surgery residents participated in the study. Stratification among medical students, junior residents, and senior residents and/or attending physicians was found in all tasks. The twenty-five medical students who were retained for longitudinal training improved significantly above junior resident level in four of the six tasks. The FORS is an effective simulator of basic motor skills that translates across a wide variety of operations and has the potential to advance junior-level participants to senior resident skill level. The FORS simulator may serve as a valuable tool for resident education. False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "QUESTION_COUNT = 1273\n",
    "\n",
    "file_name = \"9-30-test_data_150_30_5_H100.txt\"\n",
    "path = \"../../notebooks/\"\n",
    "\n",
    "file_name = path + file_name\n",
    "\n",
    "training_data_list = []\n",
    "\n",
    "with open(file_name) as f:\n",
    "    is_reading_context = False\n",
    "    context = \"\"\n",
    "\n",
    "    is_reading_question = False\n",
    "    question = \"\"\n",
    "\n",
    "    for line in f:\n",
    "        # if line == \"\\n\":\n",
    "        #     continue\n",
    "\n",
    "        stripped_line = line.strip()\n",
    "        if stripped_line == \"Context:\":\n",
    "            is_reading_context = True\n",
    "        elif stripped_line == \"Question:\":\n",
    "            is_reading_context = False\n",
    "            is_reading_question = True\n",
    "        elif stripped_line.startswith(\"[output]\"):\n",
    "            is_correct = stripped_line[len(\"[output]\"):] == \"True\"\n",
    "            context = context.strip()\n",
    "            question = question.strip()\n",
    "            data = TrainingData(context, question, is_correct)\n",
    "            # print(\"aaa\", context, question, is_correct)\n",
    "\n",
    "            training_data_list.append(data)\n",
    "\n",
    "            # if len(training_data_list) % 100 == 0:\n",
    "            #     print(f\"finished processing {len(training_data_list)} data\")\n",
    "\n",
    "            # clear\n",
    "            is_reading_context = False\n",
    "            context = \"\"\n",
    "            is_reading_question = False\n",
    "            question = \"\"\n",
    "            # break\n",
    "        else:\n",
    "            if is_reading_context:\n",
    "                context += line\n",
    "            elif is_reading_question:\n",
    "                question += line\n",
    "\n",
    "# training_data_list = training_data_list[:1000]\n",
    "print(len(training_data_list))\n",
    "print(training_data_list[0].context, training_data_list[0].is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791a2d43-2403-417c-90a0-3434b428f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47058\n",
      "Remote prognosis of preeclampsia in women 25 years old and younger. Twenty-six primiparous women less than or equal to 25 years old who delivered between 1963 and 1978 and met the following criteria were studied: (1) The first obstetric visit was at less than or equal to 30 weeks' gestation with diastolic blood pressure less than or equal to 85 mm Hg; (2) diastolic blood pressure before delivery was greater than or equal to 95-mm Hg, rising at least 15 mm Hg; (3) 24-hour urine protein measured at least 1.0 gm; and (4) patients were enrolled in the Kaiser Health Plan in 1982. Each of the 26 patients was paired with a primiparous woman by year delivered, age, race (black versus nonblack), and weight +/- 1/3. In 23 pairs blood pressure follow-up was available in 1980 or thereafter, which was at least 3 1/2 years after delivery (average interval between delivery and follow-up = 10 years). Three in the preeclampsia group and two in the matched control group had hypertension, with diastolic blood pressure greater than or equal to 90 mm Hg. Mean systolic blood pressure (123.7 mm Hg) was 9.3 mm Hg higher in the preeclampsia group than in the matched controls (114.4 mm Hg), with a standard error of 4.15 mm Hg (p = 0.04). Mean diastolic blood pressure (77.0 mm Hg) was 2.9 mm Hg higher in the preeclampsia group than in the controls (74.1 mm Hg), with a standard error of 3.0 mm Hg (p = 0.345). We conclude that no significant difference in frequency of hypertension or diastolic blood pressure and a small but significant difference in systolic blood pressure is shown in follow-up between patients with preeclampsia and matched controls. True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "QUESTION_COUNT = 10178\n",
    "\n",
    "log_file_list = [\n",
    "    \"9-20-train_150_30_1st_H100.txt\", \n",
    "    \"9-20-train_150_30_2nd_H100.txt\", \n",
    "    \"9-21-train_150_30_3rd_H100.txt\",\n",
    "    \"9-23-train_150_30_4th_H100.txt\",\n",
    "    \"9-24-train_150_30_5th_H100.txt\",\n",
    "                ]\n",
    "# log_file = \"9-20-train_150_30_2nd_H100.txt\"\n",
    "\n",
    "path = \"../../notebooks/\"\n",
    "\n",
    "file_name_list = [path + log_file for log_file in log_file_list]\n",
    "\n",
    "training_data_list = []\n",
    "\n",
    "for file_name in file_name_list:\n",
    "    with open(file_name) as f:\n",
    "        is_reading_context = False\n",
    "        context = \"\"\n",
    "    \n",
    "        is_reading_question = False\n",
    "        question = \"\"\n",
    "    \n",
    "        for line in f:\n",
    "            # if line == \"\\n\":\n",
    "            #     continue\n",
    "    \n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line == \"Context:\":\n",
    "                is_reading_context = True\n",
    "            elif stripped_line == \"Question:\":\n",
    "                is_reading_context = False\n",
    "                is_reading_question = True\n",
    "            elif stripped_line.startswith(\"[output]\"):\n",
    "                is_correct = stripped_line[len(\"[output]\"):] == \"True\"\n",
    "                context = context.strip()\n",
    "                question = question.strip()\n",
    "                data = TrainingData(context, question, is_correct)\n",
    "                # print(\"aaa\", context, question, is_correct)\n",
    "    \n",
    "                training_data_list.append(data)\n",
    "    \n",
    "                # if len(training_data_list) % 100 == 0:\n",
    "                #     print(f\"finished processing {len(training_data_list)} data\")\n",
    "    \n",
    "                # clear\n",
    "                is_reading_context = False\n",
    "                context = \"\"\n",
    "                is_reading_question = False\n",
    "                question = \"\"\n",
    "                # break\n",
    "            else:\n",
    "                if is_reading_context:\n",
    "                    context += line\n",
    "                elif is_reading_question:\n",
    "                    question += line\n",
    "\n",
    "# training_data_list = training_data_list[:1000]\n",
    "print(len(training_data_list))\n",
    "print(training_data_list[6].context, training_data_list[6].is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a35151c3-4602-422e-992d-7a692194e4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4455 955 955\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose training_data_list is your list of TrainingData objects\n",
    "data = pd.DataFrame([{\n",
    "    \"context\": d.context,\n",
    "    \"question\": d.question,\n",
    "    \"label\": int(d.is_correct)   # True->1, False->0\n",
    "} for d in training_data_list])\n",
    "\n",
    "# Train/val/test split (e.g., 70/15/15)\n",
    "train_df, temp_df = train_test_split(data, test_size=0.3, random_state=42, stratify=data[\"label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "# print(test_df.iloc[0][\"context\"])\n",
    "# print(test_df.iloc[0][\"question\"])\n",
    "print(test_df.iloc[1][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c62f910-959c-4d2f-99ed-07b332bb043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "MAX_LEN = 1024 #512\n",
    "TARGET_MAX_LEN = 2\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=MAX_LEN, target_max_len=TARGET_MAX_LEN):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.target_max_len = target_max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = self.data.loc[idx, \"context\"]\n",
    "        question = self.data.loc[idx, \"question\"]\n",
    "        label = self.data.iloc[idx][\"label\"]\n",
    "\n",
    "        input_text = f\"question: {question} context: {context}\"\n",
    "        target_text = \"yes\" if label == 1 else \"no\"\n",
    "\n",
    "        # Keep return_tensors=None, let __getitem__ return 1D tensors\n",
    "        encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.target_max_len,\n",
    "            return_tensors=None\n",
    "        )\n",
    "\n",
    "        # Convert to tensors (1D)\n",
    "        input_ids = torch.tensor(encoding[\"input_ids\"], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(encoding[\"attention_mask\"], dtype=torch.long)\n",
    "        labels = torch.tensor(target_encoding[\"input_ids\"], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c18e395-d495-4153-943e-31a0756c025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QADataset(train_df, tokenizer)\n",
    "val_dataset = QADataset(val_df, tokenizer)\n",
    "test_dataset = QADataset(test_df, tokenizer)\n",
    "all_dataset = QADataset(data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b296d1e-6b8d-4b56-ab2b-d9ac8679e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[822, 10, 71, 1640, 18, 1201, 18, 1490, 388, 28, 5274, 15803, 17688, 437, 8, 1246, 13, 968, 6621, 28, 46, 12498, 1215, 9, 2110, 115, 257, 13, 710, 655, 13, 6522, 6, 14228, 15, 457, 53, 6, 11, 19222, 53, 147, 8, 336, 633, 477, 5, 978, 17688, 1225, 3976, 33, 1086, 168, 6478, 28, 1646, 306, 18, 12051, 16, 1024, 1361, 6467, 265, 21919, 40, 782, 6, 68, 147, 8, 336, 471, 42, 78, 3, 88, 65, 1597, 3, 9, 3, 14880, 7535, 138, 19222, 11, 8248, 14228, 15, 457, 53, 3, 3565, 207, 5856, 28, 8612, 11208, 5, 71, 1132, 13, 633, 3, 7, 2388, 32, 17685, 2279, 3130, 13, 3, 13711, 1436, 138, 17688, 28, 3, 9, 11807, 19598, 2660, 2317, 799, 1343, 26359, 5, 4073, 13, 8, 826, 19, 167, 952, 12, 36, 1968, 28, 8, 1100, 1453, 13, 17688, 610, 16, 48, 1868, 58, 784, 188, 908, 3, 10, 1761, 1343, 9241, 17, 17801, 138, 3, 30920, 784, 279, 908, 3, 10, 1761, 1343, 3050, 5467, 44, 29006, 784, 254, 908, 3, 10, 1761, 1343, 16915, 784, 308, 908, 3, 10, 1761, 1343, 6676, 31847, 655, 2625, 10, 1266, 12194, 53, 17688, 16, 2749, 3513, 30, 8, 1873, 13, 3739, 892, 5, 37, 8209, 13, 17688, 19, 59, 373, 11753, 11, 54, 36, 237, 72, 4421, 16, 2749, 3513, 5, 282, 189, 51, 9, 19, 3, 20690, 5899, 57, 10686, 13, 7660, 8982, 6546, 799, 7631, 14130, 5, 611, 6, 186, 1221, 28, 17688, 103, 59, 5970, 799, 7631, 26359, 3701, 504, 3, 13711, 3995, 26, 173, 1016, 3, 60, 2660, 11102, 5, 101, 3, 8287, 12, 9127, 9689, 127, 7, 21, 3, 9, 1465, 3, 13711, 1436, 138, 1921, 794, 28, 140, 189, 9, 3995, 747, 16, 2749, 3513, 271, 14434, 21, 17688, 5, 100, 19, 3, 9, 7028, 7452, 810, 28, 3, 9, 2269, 18, 14309, 138, 408, 5, 19204, 3, 1439, 2, 3328, 203, 28, 18024, 17688, 11, 3, 9, 2841, 442, 13711, 3995, 26, 173, 1016, 1773, 30, 3, 7, 2388, 32, 17685, 130, 1285, 5, 432, 3008, 365, 16103, 3, 9, 140, 189, 9, 3995, 747, 1921, 794, 41, 3698, 382, 137, 101, 14841, 8, 701, 13, 1068, 17688, 7468, 746, 11, 1151, 3739, 746, 12, 9689, 8, 283, 6227, 772, 5, 71, 1249, 9504, 179, 28820, 26625, 825, 47, 1597, 12, 6570, 8, 11445, 13971, 1113, 53, 8, 11007, 13, 3, 9, 1465, 283, 6227, 741, 5, 421, 810, 1285, 3, 4450, 3008, 5, 37, 2942, 130, 3955, 41, 29, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 5373, 6, 489, 19162, 6210, 11, 8, 1348, 1246, 47, 431, 26346, 203, 5, 3, 3405, 28, 3, 9, 1465, 283, 6227, 41, 29, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 3769, 6, 489, 15731, 6210, 130, 72, 952, 12, 43, 14228, 15, 457, 53, 42, 19222, 53, 788, 12, 4755, 729, 7, 41, 29, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 5553, 6, 3, 4508, 5, 6170, 3, 208, 7, 5, 3, 29, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 2122, 6, 6374, 5, 6932, 117, 276, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 10667, 7256, 11, 8565, 3214, 633, 6438, 41, 29, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 2534, 6, 944, 5, 2712, 3, 208, 7, 5, 3, 29, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 4347, 4357, 5170, 6, 276, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 10667, 11728, 5, 621, 13592, 6, 578, 14228, 15, 457, 53, 42, 19222, 53, 788, 12, 4755, 729, 7, 41, 2990, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 19765, 6, 668, 2712, 3, 3597, 3, 18596, 6832, 5, 11864, 276, 1439, 2, 3, 2, 2423, 1439, 2, 3, 2, 11739, 2122, 61, 3, 7361, 8, 163, 1516, 2547, 9689, 127, 13, 3, 9, 1465, 283, 6227, 5, 86, 2749, 3513, 28, 18024, 17688, 6, 822, 53, 81, 14228, 15, 457, 53, 42, 19222, 53, 788, 12, 4755, 729, 7, 795, 3, 9, 11306, 2547, 701, 12, 9689, 3, 9, 283, 6227, 741, 16, 273, 113, 3150, 141, 3, 9, 2841, 442, 13711, 3995, 26, 173, 1016, 1773, 30, 3, 7, 2388, 32, 17685, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"input_ids\"].tolist())\n",
    "# print(len(train_dataset[2][\"input_ids\"].tolist()))\n",
    "# print(train_dataset[1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "656100dc-9f32-4936-abcc-6e819b35ddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "Input IDs: tensor([  822,    10,    71,  9212, 26429,   102,     9,    15,  4370,  3730,\n",
      "         8141,    19,     3,  8828,     3,     9,   443,  6459, 11916,  2096,\n",
      "           28,     8,  3066, 13404,    38,     8,  7078, 10027,     5,     3,\n",
      "         2092,     8,   495,     6,     8,  8141,    16,     9,    26,  3027,\n",
      "          295,   120,  8620,     3,     9,     3,  8902,   127,  2134,   106])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1])\n",
      "Labels: tensor([150,   1])\n",
      "\n",
      "Decoded input:\n",
      "question: A junior orthopaedic surgery resident is completing a carpal tunnel repair with the department chairman as the attending physician. During the case, the resident inadvertently cuts a flexor tendon. The tendon is repaired without complication. The attending tells the resident that the patient will do fine, and there is no need to report this minor complication that will not harm the patient, as he does not want to make the patient worry unnecessarily. He tells the resident to leave this complication out of the operative report. Which of the following is the correct next action for the resident to take? [A] : Disclose the error to the patient and put it in the operative report [B] : Tell the attending that he cannot fail to disclose this mistake [C] : Report the physician to the ethics committee [D] : Refuse to dictate the operative report context: A cost-effective junior resident training and assessment simulator for orthopaedic surgical skills via fundamentals of orthopaedic surgery: AAOS exhibit selection. Psychomotor testing has been recently incorporated into residency training programs not only to objectively assess a surgeon's abilities but also to address current patient-safety advocacy and medicolegal trends. The purpose of this study was to develop and test a cost-effective psychomotor training and assessment tool-The Fundamentals of Orthopaedic Surgery (FORS)-for junior-level orthopaedic surgery resident education. An orthopaedic skills board was made from supplies purchased at a local hardware store with a total cost of less than $350 so as to assess six different psychomotor skills. The six skills included fracture reduction, three-dimensional drill accuracy, simulated fluoroscopy-guided drill accuracy, depth-of-plunge minimization, drill-by-feel accuracy, and suture speed and quality. Medical students, residents, and attending physicians from three orthopaedic surgery residency programs accredited by the Accreditation Council for Graduate Medical Education participated in the study. Twenty-five medical students were retained for longitudinal training and testing for four weeks. Each training session involved an initial examination followed by thirty minutes of board training. The time to perform each task was measured with accuracy measurements for the appropriate tasks. Statistical analysis was done with one-way analysis of variance, with significance set at p &lt; 0.05. Forty-seven medical students, twenty-nine attending physicians, and fifty-eight orthopaedic surgery residents participated in the study. Stratification among medical students, junior residents, and senior residents and/or attending physicians was found in all tasks. The twenty-five medical students who were retained for longitudinal training improved significantly above junior resident level in four of the six tasks. The FORS is an effective simulator of basic motor skills that translates across a wide variety of operations and has the potential to advance junior-level participants to senior resident skill level. The FORS simulator may serve as a valuable tool for resident education.\n",
      "\n",
      "Decoded label:\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "sample = all_dataset[0]  # first element\n",
    "\n",
    "print(\"Keys:\", sample.keys())\n",
    "print(\"Input IDs:\", sample[\"input_ids\"][:50])  # first 50 tokens\n",
    "print(\"Attention Mask:\", sample[\"attention_mask\"][:50])\n",
    "print(\"Labels:\", sample[\"labels\"])\n",
    "\n",
    "# If you also want to see the decoded text:\n",
    "print(\"\\nDecoded input:\")\n",
    "print(tokenizer.decode(sample[\"input_ids\"], skip_special_tokens=True))\n",
    "\n",
    "print(\"\\nDecoded label:\")\n",
    "print(tokenizer.decode(sample[\"labels\"], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6361f087-6128-4a4f-b867-c350054a6d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_3515008/3807815030.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "output_dir = \"/projects/sciences/computing/sheju347/RAG/classifier/t5-large-epoch-10\" # \"./results\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    disable_tqdm=False,   # <-- force progress bars\n",
    ")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     from sklearn.metrics import accuracy_score, f1_score\n",
    "#     logits, labels = eval_pred\n",
    "#     preds = logits.argmax(-1)\n",
    "#     return {\n",
    "#         \"accuracy\": accuracy_score(labels, preds),\n",
    "#         \"f1\": f1_score(labels, preds)\n",
    "#     }\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    import torch\n",
    "\n",
    "    # Extract logits and labels\n",
    "    logits = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # If logits is a tuple (common for seq2seq models), take the first element\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # Convert logits to predicted token IDs\n",
    "    pred_ids = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    \n",
    "    # Decode to text\n",
    "    decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Map yes/no to 1/0\n",
    "    y_pred = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_preds]\n",
    "    \n",
    "    # True labels\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    y_true = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_labels]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0412a0d5-cfe7-49bd-a0a7-b86a4b20b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 2.452023506164551, 'test_model_preparation_time': 0.006, 'test_accuracy': 0.57, 'test_f1': 0.6526655896607432, 'test_runtime': 80.9434, 'test_samples_per_second': 24.709, 'test_steps_per_second': 12.354}\n",
      "logits [[[-31.606998  -25.20112   -26.147316  ... -68.91862   -69.15281\n",
      "   -69.22951  ]\n",
      "  [-49.78679    -2.9761786 -34.082466  ... -82.10734   -82.12439\n",
      "   -82.237495 ]]\n",
      "\n",
      " [[-29.508114  -25.409075  -29.342428  ... -69.40521   -69.70052\n",
      "   -69.633575 ]\n",
      "  [-48.09536    -2.5469418 -33.890945  ... -82.157745  -82.167625\n",
      "   -82.26117  ]]\n",
      "\n",
      " [[-31.81375   -24.463728  -26.152351  ... -63.669308  -63.797806\n",
      "   -63.80887  ]\n",
      "  [-49.5744     -2.7413807 -33.149803  ... -81.38827   -81.39487\n",
      "   -81.61076  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-35.51327   -27.692396  -29.640959  ... -70.850914  -70.93886\n",
      "   -70.99987  ]\n",
      "  [-48.06893    -2.782088  -32.50766   ... -80.66523   -80.71605\n",
      "   -80.83512  ]]\n",
      "\n",
      " [[-36.57857   -25.693094  -25.592136  ... -69.01187   -69.02375\n",
      "   -69.01892  ]\n",
      "  [-48.20813    -3.1577544 -32.17798   ... -79.960304  -80.09288\n",
      "   -80.18694  ]]\n",
      "\n",
      " [[-38.79296   -31.380194  -31.546455  ... -80.38776   -80.579956\n",
      "   -80.515015 ]\n",
      "  [-49.08514    -3.4100175 -32.87483   ... -81.52384   -81.64906\n",
      "   -81.766785 ]]]\n",
      "pred_ids tensor([[4273,    1],\n",
      "        [4273,    1],\n",
      "        [4273,    1],\n",
      "        ...,\n",
      "        [4273,    1],\n",
      "        [ 150,    1],\n",
      "        [ 150,    1]])\n",
      "decoded_preds ['yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no']\n",
      "decoded_labels ['yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes']\n",
      "Accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# test_ds = all_dataset\n",
    "# test_ds = Subset(all_dataset, range(800))\n",
    "# test_ds = Subset(test_dataset, range(800))\n",
    "# test_ds = val_dataset\n",
    "# test_ds = test_dataset\n",
    "test_ds = Subset(train_dataset, range(1000, 3000))\n",
    "# test_ds = train_dataset\n",
    "print(len(test_ds))\n",
    "\n",
    "preds = trainer.predict(test_ds)\n",
    "print(preds.metrics)  # optional, shows overall metrics\n",
    "\n",
    "# Get logits\n",
    "logits = preds.predictions  # <--- use .predictions\n",
    "\n",
    "\n",
    "# If logits is a tuple (common for seq2seq models), take the first element\n",
    "if isinstance(logits, tuple):\n",
    "    logits = logits[0]  # shape: (num_examples, seq_len, vocab_size)\n",
    "\n",
    "print(\"logits\", logits)\n",
    "# Convert logits to token IDs\n",
    "pred_ids = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "\n",
    "print (\"pred_ids\", pred_ids)\n",
    "# Decode token IDs to text\n",
    "decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer.batch_decode(preds.label_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"decoded_preds\", decoded_preds)\n",
    "print(\"decoded_labels\", decoded_labels)\n",
    "\n",
    "# Convert yes/no to 1/0\n",
    "y_pred = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_preds]\n",
    "y_true = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_labels]\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde9f936-71a9-4ae3-b29d-33ec3a89aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "total_count = 100\n",
    "correct_count = 0\n",
    "for i in range(total_count):\n",
    "    # Take one sample from the test set\n",
    "    sample = test_dataset[i]\n",
    "    \n",
    "    # Add batch dimension\n",
    "    input_ids = sample[\"input_ids\"].unsqueeze(0)       # shape [1, seq_len]\n",
    "    attention_mask = sample[\"attention_mask\"].unsqueeze(0)\n",
    "    \n",
    "    decoder_start_token_id = model.config.decoder_start_token_id\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # outputs = model.generate(\n",
    "        #     input_ids=input_ids,\n",
    "        #     attention_mask=attention_mask,\n",
    "        #     max_length=TARGET_MAX_LEN\n",
    "        # )\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=torch.tensor([[decoder_start_token_id]])\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "\n",
    "    first_token_logits = logits[0, 0]\n",
    "    print(\"first_token_logits\", first_token_logits)\n",
    "    probs = F.softmax(first_token_logits, dim=-1)\n",
    "\n",
    "    yes_id = tokenizer.encode(\"yes\", add_special_tokens=False)[0]\n",
    "    no_id = tokenizer.encode(\"no\", add_special_tokens=False)[0]\n",
    "    \n",
    "    print(\"Confidence yes:\", probs[yes_id].item())\n",
    "    print(\"Confidence no:\", probs[no_id].item())\n",
    "    \n",
    "    pred_ids = torch.argmax(logits, dim=-1)  # [batch, seq_len]\n",
    "    \n",
    "    # Decode prediction\n",
    "    pred_text = tokenizer.decode(pred_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Decode ground truth label\n",
    "    true_text = tokenizer.decode(sample[\"labels\"], skip_special_tokens=True)\n",
    "    \n",
    "    print(\"Predicted:\", pred_text)\n",
    "    print(\"True Label:\", true_text)\n",
    "    if pred_text == true_text:\n",
    "        correct_count += 1\n",
    "\n",
    "print(f\"accuracy: {correct_count / total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e224d9-608a-4192-9e43-f1a62b0f6079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a855791-aa19-49dd-ac5d-62a4112e1214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: /projects/sciences/computing/sheju347/.cache/huggingface\n",
      "HF_HUB_CACHE: /projects/sciences/computing/sheju347/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set env vars BEFORE importing huggingface modules\n",
    "os.environ[\"HF_HOME\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface/hub\"\n",
    "\n",
    "# Now import huggingface modules\n",
    "from huggingface_hub import constants\n",
    "\n",
    "print(\"HF_HOME:\", constants.HF_HOME)\n",
    "print(\"HF_HUB_CACHE:\", constants.HF_HUB_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a387e5-0079-41b2-9dfe-8e63dcc76d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainingData:\n",
    "    def __init__(self, context: str, question: str, is_correct: bool):\n",
    "        self.context = context\n",
    "        self.question = question\n",
    "        self.is_correct = is_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37146e82-d1ab-412d-9e56-f1606a6fb54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# model_name = \"google/flan-t5-large\"  # or t5-base, t5-large\n",
    "# model_name = \"google-t5/t5-base\"\n",
    "# model_name = \"google-t5/t5-small\"\n",
    "model_name = \"google-t5/t5-large\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/RAG/sentence_level_classifier/t5-large-epoch-10-3/checkpoint-853\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "944466f0-c394-429c-a47f-7d3fe074f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5925\n",
      "Frozen section investigation revealed the presence of signet cell adenocarcinoma.\n",
      "A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. She otherwise feels well and is followed by a doctor for her pregnancy. Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air. Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. Which of the following is the best treatment for this patient?\n",
      "\n",
      "[A] : Ampicillin\n",
      "[B] : Ceftriaxone\n",
      "[C] : Doxycycline\n",
      "[D] : Nitrofurantoin\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# QUESTION_COUNT = 10178\n",
    "\n",
    "# log_file_list = [\n",
    "#     \"9-20-train_150_30_1st_H100.txt\", \n",
    "#     \"9-20-train_150_30_2nd_H100.txt\", \n",
    "#     \"9-21-train_150_30_3rd_H100.txt\",\n",
    "#     \"9-23-train_150_30_4th_H100.txt\",\n",
    "#     \"9-24-train_150_30_5th_H100.txt\",\n",
    "#                 ]\n",
    "log_file_list = [\"10-7-150-30-3-sent_level_training_data.txt\"]\n",
    "# log_file_list = [\"10-7-sent_level_training_data.txt\"]\n",
    "# log_file = \"9-20-train_150_30_2nd_H100.txt\"\n",
    "\n",
    "# path = \"../../notebooks/\"\n",
    "path = \"./\"\n",
    "\n",
    "file_name_list = [path + log_file for log_file in log_file_list]\n",
    "\n",
    "training_data_list = []\n",
    "\n",
    "for file_name in file_name_list:\n",
    "    with open(file_name) as f:\n",
    "        is_reading_context = False\n",
    "        context = \"\"\n",
    "    \n",
    "        is_reading_question = False\n",
    "        question = \"\"\n",
    "    \n",
    "        for line in f:\n",
    "            # if line == \"\\n\":\n",
    "            #     continue\n",
    "    \n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line == \"Context:\":\n",
    "                is_reading_context = True\n",
    "            elif stripped_line == \"Question:\":\n",
    "                is_reading_context = False\n",
    "                is_reading_question = True\n",
    "            elif stripped_line.startswith(\"[output]\"):\n",
    "                is_correct = stripped_line[len(\"[output]\"):] == \"True\"\n",
    "                context = context.strip()\n",
    "                question = question.strip()\n",
    "                data = TrainingData(context, question, is_correct)\n",
    "                # print(\"aaa\", context, question, is_correct)\n",
    "                # if len(training_data_list) > 2000:\n",
    "                #     break\n",
    "    \n",
    "                training_data_list.append(data)\n",
    "    \n",
    "                # if len(training_data_list) % 100 == 0:\n",
    "                #     print(f\"finished processing {len(training_data_list)} data\")\n",
    "    \n",
    "                # clear\n",
    "                is_reading_context = False\n",
    "                context = \"\"\n",
    "                is_reading_question = False\n",
    "                question = \"\"\n",
    "                # break\n",
    "            else:\n",
    "                if is_reading_context:\n",
    "                    context += line\n",
    "                elif is_reading_question:\n",
    "                    question += line\n",
    "\n",
    "# training_data_list = training_data_list[:1000]\n",
    "print(len(training_data_list))\n",
    "sample = training_data_list[6]\n",
    "print(sample.context)\n",
    "print(sample.question)\n",
    "print(training_data_list[6].is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa5d205-a457-454e-93ed-7af70b86ec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_len 908.5\n",
      "1350 1350\n"
     ]
    }
   ],
   "source": [
    "# Force set data to be balanced\n",
    "adapted_data_list = []\n",
    "incorrect_count = 0\n",
    "for data in training_data_list:\n",
    "    if data.is_correct == False:\n",
    "        incorrect_count += 1\n",
    "\n",
    "counter = 0\n",
    "for data in training_data_list:\n",
    "    if data.is_correct == False:\n",
    "        adapted_data_list.append(data)\n",
    "    else:\n",
    "        if counter < incorrect_count + 0:\n",
    "            adapted_data_list.append(data)\n",
    "            counter += 1\n",
    "\n",
    "training_data_list = adapted_data_list\n",
    "\n",
    "\n",
    "# Change the label based on length\n",
    "lengths = []\n",
    "for data in training_data_list:\n",
    "    lengths.append(len(data.context) + len(data.question))\n",
    "import statistics\n",
    "median_len = statistics.median(lengths)\n",
    "print(\"median_len\", median_len)\n",
    "\n",
    "# for data in training_data_list:\n",
    "#     if (len(data.context) + len(data.question)) > median_len:\n",
    "#         data.is_correct = True\n",
    "#     else:\n",
    "#         data.is_correct = False\n",
    "    \n",
    "\n",
    "false_count = 0\n",
    "true_count = 0\n",
    "for data in training_data_list:\n",
    "    if data.is_correct:\n",
    "        true_count += 1\n",
    "    else:\n",
    "        false_count += 1\n",
    "print(false_count, true_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4179036-f45c-4f78-a304-af7fe770b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"./data/cfimdb-train.txt\"\n",
    "\n",
    "# training_data_list = []\n",
    "\n",
    "# with open(filename, 'r') as fp:\n",
    "#     for line in fp:\n",
    "#         label, org_sent = line.split(' ||| ')\n",
    "#         # sent = org_sent.lower().strip()\n",
    "#         # tokens = tokenizer.tokenize(\"[CLS] \" + sent + \" [SEP]\")\n",
    "#         label = int(label.strip())\n",
    "#         # if label not in num_labels:\n",
    "#         #     num_labels[label] = len(num_labels)\n",
    "#         data = TrainingData(org_sent, \"\", label)\n",
    "#         training_data_list.append(data)\n",
    "\n",
    "# print(training_data_list[6].context, training_data_list[6].is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "262fb3be-46cb-413a-af94-6263ad3fd066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1890 405 405\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose training_data_list is your list of TrainingData objects\n",
    "data = pd.DataFrame([{\n",
    "    \"context\": d.context,\n",
    "    \"question\": d.question,\n",
    "    \"label\": int(d.is_correct)   # True->1, False->0\n",
    "} for d in training_data_list])\n",
    "\n",
    "# Train/val/test split (e.g., 70/15/15)\n",
    "train_df, temp_df = train_test_split(data, test_size=0.3, random_state=42, stratify=data[\"label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n",
    "\n",
    "\n",
    "# # Don't shuffle\n",
    "# n = len(data)\n",
    "# train_end = int(0.7 * n)\n",
    "# val_end = int(0.85 * n)  # 70% train, 15% val, 15% test\n",
    "\n",
    "# # Split sequentially (no shuffle)\n",
    "# train_df = data.iloc[:train_end]\n",
    "# val_df = data.iloc[train_end:val_end]\n",
    "# test_df = data.iloc[val_end:]\n",
    "\n",
    "\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "# print(test_df.iloc[0][\"context\"])\n",
    "# print(test_df.iloc[0][\"question\"])\n",
    "print(test_df.iloc[1][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7727bf-228c-416a-a9dc-c2196df3bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in train_df.iterrows():\n",
    "#     print(f'{row[\"context\"]} {row[\"label\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9622e517-6e51-4ef2-b918-2084d49e3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "MAX_LEN = 1024 #512\n",
    "TARGET_MAX_LEN = 2\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=MAX_LEN, target_max_len=TARGET_MAX_LEN):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.target_max_len = target_max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = self.data.loc[idx, \"context\"]\n",
    "        question = self.data.loc[idx, \"question\"]\n",
    "        label = self.data.iloc[idx][\"label\"]\n",
    "\n",
    "        input_text = f\"question: {question} context: {context}\"\n",
    "        target_text = \"yes\" if label == 1 else \"no\"\n",
    "\n",
    "        # Keep return_tensors=None, let __getitem__ return 1D tensors\n",
    "        encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.target_max_len,\n",
    "            return_tensors=None\n",
    "        )\n",
    "\n",
    "        # Convert to tensors (1D)\n",
    "        input_ids = torch.tensor(encoding[\"input_ids\"], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(encoding[\"attention_mask\"], dtype=torch.long)\n",
    "        labels = torch.tensor(target_encoding[\"input_ids\"], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "348b73ad-cb3b-41bd-ad2c-d05cde94d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QADataset(train_df, tokenizer)\n",
    "val_dataset = QADataset(val_df, tokenizer)\n",
    "test_dataset = QADataset(test_df, tokenizer)\n",
    "all_dataset = QADataset(data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd059b2-9f45-4225-b8fa-003cfd40a0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[822, 10, 71, 3, 3539, 18, 1201, 18, 1490, 2335, 28, 6658, 3, 32, 115, 7593, 757, 3, 26836, 1994, 19, 1940, 12, 8, 3583, 3066, 250, 13, 17055, 6, 643, 3, 14693, 6, 1460, 8284, 6, 11, 3, 9, 2192, 19222, 5, 451, 65, 3, 24198, 80, 4153, 13, 22893, 1444, 21, 604, 203, 68, 10399, 10257, 209, 215, 977, 5, 451, 1342, 28, 160, 3062, 11, 160, 30963, 6, 113, 2467, 7, 239, 2864, 5, 1347, 2912, 19, 220, 20677, 1956, 254, 41, 19621, 1956, 371, 137, 15576, 6498, 1267, 24097, 975, 6959, 75, 5499, 155, 159, 6, 29586, 52, 52, 88, 9, 6, 11, 3, 4203, 532, 3357, 1162, 8760, 1558, 406, 1215, 76, 5522, 7, 5, 9006, 2505, 3606, 7, 7952, 28, 46, 14669, 26, 26429, 2258, 226, 32, 18095, 5, 6863, 13, 3, 9, 2672, 28, 84, 13, 8, 826, 12009, 13, 1041, 19, 167, 2016, 58, 784, 188, 908, 3, 10, 86, 13506, 1575, 13, 206, 2482, 32, 1583, 7211, 20146, 9, 7, 15, 784, 279, 908, 3, 10, 86, 13506, 1575, 13, 23844, 29, 3017, 14836, 784, 254, 908, 3, 10, 86, 13506, 1575, 13, 3, 29, 1238, 9, 7619, 7664, 15, 784, 308, 908, 3, 10, 86, 13506, 1575, 13, 22618, 9, 7, 15, 2625, 10, 4004, 222, 2252, 9413, 3217, 8248, 3, 32, 5379, 2420, 16, 8, 14701, 13, 8, 3, 17454, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[9][\"input_ids\"].tolist())\n",
    "# print(len(train_dataset[2][\"input_ids\"].tolist()))\n",
    "# print(train_dataset[1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bc2616a-d027-4986-8215-3a39d64c774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90852/778904191.py:60: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "output_dir = \"/projects/sciences/computing/sheju347/RAG/sentence_level_classifier/t5-large-epoch-10-5\" # \"./results\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     from sklearn.metrics import accuracy_score, f1_score\n",
    "#     logits, labels = eval_pred\n",
    "#     preds = logits.argmax(-1)\n",
    "#     return {\n",
    "#         \"accuracy\": accuracy_score(labels, preds),\n",
    "#         \"f1\": f1_score(labels, preds)\n",
    "#     }\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    import torch\n",
    "\n",
    "    # Extract logits and labels\n",
    "    logits = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # If logits is a tuple (common for seq2seq models), take the first element\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # Convert logits to predicted token IDs\n",
    "    pred_ids = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    \n",
    "    # Decode to text\n",
    "    decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Map yes/no to 1/0\n",
    "    y_pred = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_preds]\n",
    "    \n",
    "    # True labels\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    y_true = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_labels]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6daf404-ecf4-44d3-a3c9-8a368a88ac97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9450' max='9450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9450/9450 53:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.434155</td>\n",
       "      <td>0.883951</td>\n",
       "      <td>0.893424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227200</td>\n",
       "      <td>0.202204</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.913462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.182523</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.929907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>0.171232</td>\n",
       "      <td>0.920988</td>\n",
       "      <td>0.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.186721</td>\n",
       "      <td>0.930864</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.152296</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.928910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.162545</td>\n",
       "      <td>0.928395</td>\n",
       "      <td>0.931442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.193223</td>\n",
       "      <td>0.930864</td>\n",
       "      <td>0.933014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.124300</td>\n",
       "      <td>0.189722</td>\n",
       "      <td>0.928395</td>\n",
       "      <td>0.929782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.201653</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.927536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9450, training_loss=0.16622769875501198, metrics={'train_runtime': 3186.7065, 'train_samples_per_second': 5.931, 'train_steps_per_second': 2.965, 'total_flos': 8.18387877888e+16, 'train_loss': 0.16622769875501198, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eee8ea-d6c1-46fc-9329-b5f7cefc4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# test_ds = all_dataset\n",
    "# test_ds = Subset(all_dataset, range(800))\n",
    "# test_ds = Subset(test_dataset, range(800))\n",
    "# test_ds = val_dataset\n",
    "test_ds = test_dataset\n",
    "# test_ds = Subset(train_dataset, range(1000, 3000))\n",
    "# test_ds = train_dataset\n",
    "print(len(test_ds))\n",
    "\n",
    "preds = trainer.predict(test_ds)\n",
    "\n",
    "print(preds.metrics)  # optional, shows overall metrics\n",
    "\n",
    "# Get logits\n",
    "logits = preds.predictions  # <--- use .predictions\n",
    "\n",
    "\n",
    "# If logits is a tuple (common for seq2seq models), take the first element\n",
    "if isinstance(logits, tuple):\n",
    "    logits = logits[0]  # shape: (num_examples, seq_len, vocab_size)\n",
    "\n",
    "print(\"logits\", logits)\n",
    "# Convert logits to token IDs\n",
    "pred_ids = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "\n",
    "print (\"pred_ids\", pred_ids)\n",
    "# Decode token IDs to text\n",
    "decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer.batch_decode(preds.label_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"decoded_preds\", decoded_preds)\n",
    "print(\"decoded_labels\", decoded_labels)\n",
    "\n",
    "# Convert yes/no to 1/0\n",
    "y_pred = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_preds]\n",
    "y_true = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_labels]\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a48550-f979-4c48-a338-e137073a3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# trainer.args.predict_with_generate = False  # make sure no .generate()\n",
    "\n",
    "chunk_size = 500  # adjust depending on your GPU memory\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "\n",
    "for start in range(0, len(test_dataset), chunk_size):\n",
    "    end = min(start + chunk_size, len(test_dataset))\n",
    "    subset = Subset(test_dataset, range(start, end))\n",
    "    preds = trainer.predict(subset)\n",
    "\n",
    "    logits = preds.predictions\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    all_logits.append(logits)\n",
    "    all_labels.append(preds.label_ids)\n",
    "\n",
    "# Concatenate all chunks\n",
    "logits = np.concatenate(all_logits, axis=0)\n",
    "labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(\"logits shape:\", logits.shape)\n",
    "\n",
    "# Convert logits to predicted token IDs\n",
    "pred_ids = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "\n",
    "# Only take the first token for yes/no classification\n",
    "first_token_ids = pred_ids[:, 0]\n",
    "\n",
    "# Decode predictions and labels\n",
    "decoded_preds = tokenizer.batch_decode(first_token_ids, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(\"decoded_preds sample:\", decoded_preds[:20])\n",
    "print(\"decoded_labels sample:\", decoded_labels[:20])\n",
    "\n",
    "# Map yes/no to 1/0\n",
    "y_pred = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_preds]\n",
    "y_true = [1 if x.strip().lower() == \"yes\" else 0 for x in decoded_labels]\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9357a5-391c-466f-bed7-517daf0588d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(test_dataset)\n",
    "print(preds)\n",
    "y_pred = preds.predictions.argmax(-1)\n",
    "y_true = preds.label_ids\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4f2d9-1a80-4d0d-aa99-c9778e7b6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = preds.predictions.argmax(-1)\n",
    "count_predict_1 = 0\n",
    "count_label_1 = 0\n",
    "for i in range(len(test_dataset)):\n",
    "    if i < 20:\n",
    "        print(sum(test_dataset[i][\"attention_mask\"]), test_dataset[i][\"labels\"], y_preds[i])\n",
    "    count_predict_1 += y_preds[i]\n",
    "    count_label_1 += test_dataset[i][\"labels\"].item()\n",
    "\n",
    "print(count_predict_1, \"/\", len(test_dataset), count_predict_1 / len(test_dataset))\n",
    "print(count_label_1, \"/\", len(test_dataset), count_label_1 / len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6108352-60d6-41fb-ad7e-5a3b09584162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM311)",
   "language": "python",
   "name": "llm311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eff5bcd-c545-4a20-b37b-30f0d56e1602",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "!export CUDA_LAUNCH_BLOCKING=1   # (optional, helps debug determinism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99151ab-4029-40b5-8afd-9a74f5d95626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: /projects/sciences/computing/sheju347/.cache/huggingface\n",
      "HF_HUB_CACHE: /projects/sciences/computing/sheju347/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set env vars BEFORE importing huggingface modules\n",
    "os.environ[\"HF_HOME\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/projects/sciences/computing/sheju347/.cache/huggingface/hub\"\n",
    "\n",
    "# Now import huggingface modules\n",
    "from huggingface_hub import constants\n",
    "\n",
    "print(\"HF_HOME:\", constants.HF_HOME)\n",
    "print(\"HF_HUB_CACHE:\", constants.HF_HUB_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349a8d9c-2c15-4b55-815b-a696377a14ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/sciences/computing/sheju347/miniconda3/envs/LLM311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/projects/sciences/computing/sheju347/miniconda3/envs/LLM311/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from model_trainer import ModelTrainer\n",
    "from test_performance import TestPerformance, DatasetPath, MMLU_Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "283a1066-2c5f-47e4-86ab-2b539229b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- start checking GPU -----------\n",
      "GPU: NVIDIA H100 NVL\n",
      "torch.cuda.is_bf16_supported():  True\n",
      "---------- finish checking GPU -----------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tokenizer class TokenizersBackend does not exist or is not currently imported.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[32m     39\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mmistralai/Ministral-3-3B-Instruct-2512\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m trainer.load_model(model_name, tokenizer = tokenizer, trust_remote_code = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# trainer.load_model(model_name, lora_adapter_path)\u001b[39;00m\n\u001b[32m     45\u001b[39m \n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# tokenizer_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_qwen/11-25-qwen-4B-Thinking-UltraMedical\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# trainer.load_model_t5(model_name)\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# trainer.test_model_MedQA_response()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projects/sciences/computing/sheju347/miniconda3/envs/LLM311/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:1113\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1111\u001b[39m         tokenizer_class = tokenizer_class_from_name(tokenizer_class_candidate)\n\u001b[32m   1112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1113\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1114\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist or is not currently imported.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1115\u001b[39m         )\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Tokenizer class TokenizersBackend does not exist or is not currently imported."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "# model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# model_name = \"KrithikV/MedMobile\"\n",
    "# model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "# model_name = \"Qwen/Qwen3-4B-Thinking-2507\"\n",
    "model_name = \"mistralai/Ministral-3-3B-Instruct-2512\"\n",
    "# model_name = os.path.abspath(\"../../../projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_model_entire_UltraMedical_batch_4\")\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_model_entire_UltraMedical_batch_4\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/10-15-UltraMedical-batchsize8-lr2e-5-bf16\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/10-15-UltraMedical-batchsize8-bf16\" # BEST\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-1-phi3-mini-batchsize8-epoch456/\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_qwen/11-25-qwen-4B-Thinking-batch8-epoch456/checkpoint-256000\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-1-phi3-mini-batchsize8-epoch456/checkpoint-256000\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_phi4/11-24-phi4-mini-base-UltraMedical\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_Phi_3_mini\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_model_no_mask_entire\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/10-3-fine-tuned-all\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/10-5-fine-tuned-UltraMedical-MedQA-context/\"\n",
    "# model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/10-6-fine-tuned-UltraMedical-MedQA-LoRA\"\n",
    "\n",
    "# lora_adapter_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/10-6-fine-tuned-UltraMedical-MedQA-LoRA\"\n",
    "# lora_adapter_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/10-10-LoRA-context012-r-16-lr-1e-5\"\n",
    "# lora_adapter_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/10-12-LoRA-Evol-context012-r-16-lr-1e-5-epoch3/checkpoint-37846\"\n",
    "# lora_adapter_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/LoRA/10-17-new-base-model-1e-4-batch8-LoRA-1e-4-r16\" # BEST\n",
    "# lora_adapter_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/LoRA/12-6-epoch5-model-LoRA-1e-4-r16-context012\"\n",
    "lora_adapter_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/LoRA/12-7-epoch5-model-LoRA-1e-4-r16-context01\"\n",
    "# lora_adapter_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/LoRA/11-10-LoRA-5e-5-r16-context012\"\n",
    "\n",
    "# from transformers import Mistral3ForConditionalGeneration, MistralCommonBackend\n",
    "\n",
    "# tokenizer = MistralCommonBackend.from_pretrained(model_name)\n",
    "# model_name = \"google/flan-t5-xl\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"mistralai/Ministral-3-3B-Instruct-2512\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "trainer.load_model(model_name, tokenizer = tokenizer, trust_remote_code = True)\n",
    "# trainer.load_model(model_name, lora_adapter_path)\n",
    "\n",
    "# tokenizer_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base_qwen/11-25-qwen-4B-Thinking-UltraMedical\"\n",
    "# trainer.load_model(model_name, tokenizer_path = tokenizer_path)\n",
    "\n",
    "# tokenizer_path = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/base/12-1-phi3-mini-batchsize8-epoch456/\"\n",
    "# trainer.load_model(model_name, tokenizer_path = tokenizer_path, lora_adapter_path = lora_adapter_path)\n",
    "\n",
    "# trainer.load_model_t5(model_name)\n",
    "# trainer.test_model_MedQA_response()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8ba9d5c-f317-4dab-87e1-e7b17acbfccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.55.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f89ba-3ca3-4a20-a563-41e6aa1a6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = TestPerformance(trainer.model, trainer.tokenizer, trainer.device, is_encoder_decoder = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50774f0-7b2f-47aa-9cec-7a32401c90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_range = [9, 13, 19, 24, 28, 29, 30, 31, 32, 38, 43, 44, 45, 46, 52, 56, 57, 62, 64, 68, 71, 73, 77, 87, 90, 94, 96, 97, 108, \n",
    "#               109, 110, 118, 123, 126, 133, 135, 139, 141, 143, 144, 145, 146, 159, 160, 166, 167, 170, 171, 172, 173, 179, 180, 181, 183, \n",
    "#               185, 186, 188, 191, 196, 197, 203, 205]\n",
    "\n",
    "# data_range = range(30, 32) # None #range(34, 35)\n",
    "\n",
    "data_range = None\n",
    "\n",
    "# data_range = range(7333, 10178)\n",
    "\n",
    "# data_range = range(1117, 1273)\n",
    "\n",
    "# data_range = range(889, 1000)\n",
    "\n",
    "data_range = [3]\n",
    "\n",
    "topK_searchEngine = 150\n",
    "topK_SPLADE = 30\n",
    "topK_denseEmbedding = 1\n",
    "topK_crossEncoder = 0\n",
    "topK_LLM = 0\n",
    "score_threshold = None #0.7 # 0.8\n",
    "pick_rag_index = None\n",
    "get_classifier_training_data = False\n",
    "use_classifier = False\n",
    "RRF_models = None #[(\"SPLADE\", 0.8), (\"MonoT5\", 1), (\"Vicuna\", 1)] # [\"SPLADE\", \"DenseEmbedding\", \"MonoT5\", \"Zephyr\", \"Vicuna\"]\n",
    "\n",
    "# file_name = \"9-30-test_data_150_30_5_H100.txt\"\n",
    "# file_name = \"a.txt\"\n",
    "# file_name = \"10-14-lora-context012-r16-epoch3-150-30-5-all-data.txt\"\n",
    "# file_name = \"10-21-batchsize8-lr1e-4-bf16-new-lora-150-30-5-RRF.txt\"\n",
    "# file_name = \"11-4-150-30-5-1-MedQA-ensemble.txt\"\n",
    "# file_name = \"11-7-no-rag-ensemble-MedQA-A100.txt\"\n",
    "# file_name = \"11-13-Phi3-150-dense30-monoT51.txt\"\n",
    "# file_name = \"11-16-Phi3-1000-300-80-5-1.txt\"\n",
    "# file_name = \"11-18-Phi3-150-30-1-MonoT5-MedMCQA.txt\"\n",
    "# file_name = \"11-25-Phi3-no-rag-ensemble-train.txt\"\n",
    "# file_name = \"11-26-Phi4-no-rag-MedQA.txt\"\n",
    "# file_name = \"11-26-Phi2.5-3b-no-rag-MedMCQA.txt\"\n",
    "# file_name = \"12-1-Phi3-150-30-1-MiniLM-MMLU-College_medicine.txt\"\n",
    "# file_name = \"12-3-Phi3-batchsize8-epoch5-MedQA-ensemble.txt\"\n",
    "# file_name = \"12-5-qwen-4b-thinking-epoch5-MedQA.txt\"\n",
    "file_name = \"12-8-Phi3-epoch5-lora01-MedQA-150-30-1-Embedding.txt\"\n",
    "\n",
    "test.MAX_TOKEN_OUTPUT = 10000\n",
    "# test.SPLIT = \"train\"\n",
    "test.test_accuracy(DatasetPath.MedQA, subset_name = None, is_ensemble = False, use_RAG = True, data_range = data_range, file_name = file_name,\n",
    "                  topK_searchEngine = topK_searchEngine, topK_SPLADE = topK_SPLADE, topK_denseEmbedding = topK_denseEmbedding, topK_crossEncoder = topK_crossEncoder, topK_LLM = topK_LLM,\n",
    "                   score_threshold = score_threshold, pick_rag_index = pick_rag_index, get_classifier_training_data = get_classifier_training_data,\n",
    "                  use_classifier = use_classifier, RRF_models = RRF_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bb94f-c47d-4e92-9503-a873737c72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"10-22-150-30-5-1-MMLU-College_medicine.txt\"\n",
    "\n",
    "test.test_accuracy(DatasetPath.MMLU, subset_name = MMLU_Subset.College_medicine, is_ensemble = False, use_RAG = False, data_range = data_range, file_name = file_name,\n",
    "                  topK_searchEngine = topK_searchEngine, topK_SPLADE = topK_SPLADE, topK_denseEmbedding = topK_denseEmbedding, topK_crossEncoder = topK_crossEncoder, topK_LLM = topK_LLM,\n",
    "                   score_threshold = score_threshold, pick_rag_index = pick_rag_index, get_classifier_training_data = get_classifier_training_data,\n",
    "                  use_classifier = use_classifier, RRF_models = RRF_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0a7ea-499c-404e-85c6-d483ed7db3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"10-22-150-30-5-1-MMLU-College_biology.txt\"\n",
    "\n",
    "test.test_accuracy(DatasetPath.MMLU, subset_name = MMLU_Subset.College_biology, is_ensemble = False, use_RAG = False, data_range = data_range, file_name = file_name,\n",
    "                  topK_searchEngine = topK_searchEngine, topK_SPLADE = topK_SPLADE, topK_denseEmbedding = topK_denseEmbedding, topK_crossEncoder = topK_crossEncoder, topK_LLM = topK_LLM,\n",
    "                   score_threshold = score_threshold, pick_rag_index = pick_rag_index, get_classifier_training_data = get_classifier_training_data,\n",
    "                  use_classifier = use_classifier, RRF_models = RRF_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21e5bd-164d-4cef-a440-0cbc8b753a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"10-22-150-30-5-1-MMLU-Anatomy.txt\"\n",
    "\n",
    "test.test_accuracy(DatasetPath.MMLU, subset_name = MMLU_Subset.Anatomy, is_ensemble = False, use_RAG = False, data_range = data_range, file_name = file_name,\n",
    "                  topK_searchEngine = topK_searchEngine, topK_SPLADE = topK_SPLADE, topK_denseEmbedding = topK_denseEmbedding, topK_crossEncoder = topK_crossEncoder, topK_LLM = topK_LLM,\n",
    "                   score_threshold = score_threshold, pick_rag_index = pick_rag_index, get_classifier_training_data = get_classifier_training_data,\n",
    "                  use_classifier = use_classifier, RRF_models = RRF_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccadd8ba-2342-44b2-8995-be126c456a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"10-22-150-30-5-1-MMLU-Medical_genetics.txt\"\n",
    "\n",
    "test.test_accuracy(DatasetPath.MMLU, subset_name = MMLU_Subset.Medical_genetics, is_ensemble = False, use_RAG = False, data_range = data_range, file_name = file_name,\n",
    "                  topK_searchEngine = topK_searchEngine, topK_SPLADE = topK_SPLADE, topK_denseEmbedding = topK_denseEmbedding, topK_crossEncoder = topK_crossEncoder, topK_LLM = topK_LLM,\n",
    "                   score_threshold = score_threshold, pick_rag_index = pick_rag_index, get_classifier_training_data = get_classifier_training_data,\n",
    "                  use_classifier = use_classifier, RRF_models = RRF_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850ee99-e581-4643-a5d2-a2187f98fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"10-22-150-30-5-1-MMLU-Clinical_knowledge.txt\"\n",
    "\n",
    "test.test_accuracy(DatasetPath.MMLU, subset_name = MMLU_Subset.Clinical_knowledge, is_ensemble = False, use_RAG = False, data_range = data_range, file_name = file_name,\n",
    "                  topK_searchEngine = topK_searchEngine, topK_SPLADE = topK_SPLADE, topK_denseEmbedding = topK_denseEmbedding, topK_crossEncoder = topK_crossEncoder, topK_LLM = topK_LLM,\n",
    "                   score_threshold = score_threshold, pick_rag_index = pick_rag_index, get_classifier_training_data = get_classifier_training_data,\n",
    "                  use_classifier = use_classifier, RRF_models = RRF_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c82f5ba-8f30-403f-bd01-4d8205710349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_range = [9, 13, 19, 24, 28, 29, 30, 31, 32, 38, 43, 44, 45, 46, 52, 56, 57, 62, 64, 68, 71, 73, 77, 87, 90, 94, 96, 97, 108, \n",
    "#               109, 110, 118, 123, 126, 133, 135, 139, 141, 143, 144, 145, 146, 159, 160, 166, 167, 170, 171, 172, 173, 179, 180, 181, 183, \n",
    "#               185, 186, 188, 191, 196, 197, 203, 205]\n",
    "\n",
    "# data_range = range(4, 5) # None #range(34, 35)\n",
    "\n",
    "data_range = None\n",
    "\n",
    "# data_range = range(763, 1273)\n",
    "\n",
    "topK_searchEngine = 150\n",
    "topK_SPLADE = 30\n",
    "topK_crossEncoder = 5\n",
    "topK_LLM = 0\n",
    "score_threshold = None # 0.8\n",
    "pick_rag_index = 4\n",
    "\n",
    "file_name = \"9-5-150_30_5th_RAG_data_H100.txt\"\n",
    "# file_name = \"a.txt\"\n",
    "\n",
    "test.test_accuracy(DatasetPath.MedQA, subset_name = None, is_ensemble = False, use_RAG = True, data_range = data_range, file_name = file_name,\n",
    "                  topK_searchEngine = topK_searchEngine, topK_SPLADE = topK_SPLADE, topK_crossEncoder = topK_crossEncoder, topK_LLM = topK_LLM,\n",
    "                   score_threshold = score_threshold, pick_rag_index = pick_rag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95867a73-0d71-4739-8d85-68ba0cd8b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_prompt = \"\"\"You are a medical question answering assistant.\n",
    "\n",
    "\n",
    "\n",
    "Question:\n",
    "A 2-year-old boy is brought to the physician because of decreased appetite and abdominal pain for the last several weeks. Physical examination shows a well-appearing toddler with a palpable left-sided abdominal mass that does not cross the midline. A CT of the abdomen shows a large, necrotic tumor on the left kidney. Histological examination of the kidney mass shows primitive blastemal cells and immature tubules and glomeruli. This tissue is most likely derived from the same embryological structure as which of the following?\n",
    "\n",
    "[A] : Adrenal medulla\n",
    "[B] : Thyroid gland\n",
    "[C] : Papillary muscles\n",
    "[D] : Anterior pituitary\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": f\"{model_prompt}\"}]\n",
    "\n",
    "inputs = trainer.tokenizer.apply_chat_template(messages, add_generation_prompt = True, return_tensors = \"pt\").to(trainer.device)\n",
    "\n",
    "generate_kwargs = { \"max_new_tokens\": 1024, \"do_sample\": False }\n",
    "\n",
    "outputs = trainer.model.generate(inputs, **generate_kwargs)\n",
    "\n",
    "text = trainer.tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc516c-a20d-4ff8-b66e-07af418003ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "QUESTION_COUNT = 1273\n",
    "\n",
    "path = \"\"\n",
    "file_names = [\"9-5-150_30_1_RAG_data_H100.txt\", \"9-5-150_30_2nd_RAG_data_H100.txt\", \"9-5-150_30_3rd_RAG_data_H100.txt\", \n",
    "              \"9-5-150_30_4th_RAG_data_H100.txt\", \"9-5-150_30_5th_RAG_data_H100.txt\"]\n",
    "\n",
    "full_file_names = [path + file_name for file_name in file_names]\n",
    "\n",
    "class QuestionAnswerData:\n",
    "    def __init__(self, answer, correct_answer, RAG_data):\n",
    "        self.answer = answer\n",
    "        self.correct_answer = correct_answer\n",
    "        self.is_correct = answer == correct_answer\n",
    "        # RAG data: [{'docId': 'pubmed23n0827_1593', 'BM25_score': 95.4198, 'BM25_ranking': 44, 'SPLADE_score': 54.33488464355469, 'SPLADE_ranking': 13, 'MonoT5_score': 0.9597430488962883, 'MonoT5_ranking': 1}]\n",
    "        self.RAG_data = RAG_data\n",
    "\n",
    "# Get the data\n",
    "\n",
    "# [ [QuestionAnswerData, QuestionAnswerData, ... (1273 data)], [...], [...], [...], [...] ]\n",
    "all_question_answer_data_list = []\n",
    "\n",
    "for i in range(len(full_file_names)):\n",
    "    question_answer_data_list = []\n",
    "    with open(full_file_names[i], \"r\") as f:\n",
    "        count = 0\n",
    "        curr_RAG_data = None\n",
    "        for line in f:\n",
    "            if \"RAG data: \" in line:\n",
    "                curr_RAG_data_str = line[line.find(\"RAG data: \") + len(\"RAG data: \"):].strip()\n",
    "                curr_RAG_data = ast.literal_eval(curr_RAG_data_str)\n",
    "\n",
    "            elif \"question \" in line:\n",
    "                \n",
    "                # Check question number error\n",
    "                count += 1\n",
    "                if \"num:\" in line:\n",
    "                    number = line.strip().split('num:')[-1].split(' ')[0]\n",
    "                else:\n",
    "                    number = line.strip().split('/')[0].split(' ')[-1]\n",
    "                if int(number) != count:\n",
    "                    print(f\"Error: {file_names[i]}:\", number, count)\n",
    "                    break\n",
    "\n",
    "                match = re.search(r\"answer:([^\\s]+)\\s+correct_answer:([^\\s]+)\", line)\n",
    "                if match:\n",
    "                    answer = match.group(1)\n",
    "                    correct_answer = match.group(2)\n",
    "\n",
    "                    question_answer_data = QuestionAnswerData(answer, correct_answer, curr_RAG_data)\n",
    "                    question_answer_data_list.append(question_answer_data)\n",
    "    \n",
    "    all_question_answer_data_list.append(question_answer_data_list)\n",
    "\n",
    "print(len(all_question_answer_data_list[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2315c00-de10-4c9f-b8fd-5d6a3cf70784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM311)",
   "language": "python",
   "name": "llm311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

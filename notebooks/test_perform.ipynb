{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349a8d9c-2c15-4b55-815b-a696377a14ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheju347/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model_trainer import ModelTrainer\n",
    "from test_performance import TestPerformance, DatasetPath, MMLU_Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283a1066-2c5f-47e4-86ab-2b539229b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- start checking GPU -----------\n",
      "GPU: NVIDIA H100 NVL\n",
      "torch.cuda.is_bf16_supported():  True\n",
      "---------- finish checking GPU -----------\n",
      "---------- start loading model:/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_model_entire_UltraMedical_batch_4 -----------\n",
      "finish loading tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading model\n",
      "torch_dtype: torch.float32\n",
      "cuda available: True\n",
      "device: cuda\n",
      "---------- finish loading model:/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_model_entire_UltraMedical_batch_4 -----------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "# model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# model_name = os.path.abspath(\"../../../projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_model_entire_UltraMedical_batch_4\")\n",
    "model_name = \"/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_model_entire_UltraMedical_batch_4\"\n",
    "# model_name = \"google/flan-t5-xl\"\n",
    "\n",
    "trainer.load_model(model_name)\n",
    "# trainer.load_model_t5(model_name)\n",
    "# trainer.test_model_MedQA_response()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a49ac8-fa36-4c48-963f-75c1ce714629",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://ondemand.otago.ac.nz/home/projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_model_entire_UltraMedical_batch_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4af977-be3b-4440-9f91-8b1200395085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: /projects/sciences/computing/sheju347/MedicalQA/train/saved_models/fine_tuned_model_entire_UltraMedical_batch_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reranked top k score: [-0.8158773, -0.8480601, -1.3686457]\n",
      "question 1/1273 answer:B correct_answer:B True\n",
      "reranked top k score: [-4.3700304, -5.3764153, -5.825001]\n",
      "question 2/1273 answer:D correct_answer:D True\n",
      "reranked top k score: [-3.7423773, -4.066557, -5.0958023]\n",
      "question 3/1273 answer:A correct_answer:B False\n",
      "reranked top k score: [-1.6357648, -1.7770984, -2.155676]\n",
      "question 4/1273 answer:D correct_answer:D True\n",
      "reranked top k score: [-0.6621198, -0.7818354, -0.8809782]\n",
      "question 5/1273 answer:B correct_answer:B True\n",
      "reranked top k score: [2.6340055, 2.2501125, 1.5073938]\n",
      "question 6/1273 answer:D correct_answer:D True\n",
      "reranked top k score: [3.076138, 2.3729076, 2.1508884]\n",
      "question 7/1273 answer:C correct_answer:C True\n",
      "reranked top k score: [-0.97630084, -1.207248, -1.2318461]\n",
      "question 8/1273 answer:C correct_answer:C True\n",
      "reranked top k score: [-0.35251087, -0.6186423, -0.6682904]\n",
      "question 9/1273 answer:D correct_answer:B False\n",
      "reranked top k score: [2.1236079, 1.4422977, 0.9007847]\n",
      "question 10/1273 answer:C correct_answer:A False\n",
      "reranked top k score: [-2.4971159, -2.890932, -3.0230978]\n",
      "question 11/1273 answer:D correct_answer:D True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = TestPerformance(trainer.model, trainer.tokenizer, trainer.device, is_encoder_decoder = False)\n",
    "# test.test_accuracy(DatasetPath.MMLU, subset_name = MMLU_Subset.College_medicine, is_ensemble = False)\n",
    "# data_range = [9, 13, 19, 24, 28, 29, 30, 31, 32, 38, 43, 44, 45, 46, 52, 56, 57, 62, 64, 68, 71, 73, 77, 87, 90, 94, 96, 97, 108, \n",
    "#               109, 110, 118, 123, 126, 133, 135, 139, 141, 143, 144, 145, 146, 159, 160, 166, 167, 170, 171, 172, 173, 179, 180, 181, 183, \n",
    "#               185, 186, 188, 191, 196, 197, 203, 205]\n",
    "\n",
    "#range(205, 206) # None #range(34, 35)\n",
    "\n",
    "data_range = None\n",
    "\n",
    "topK_searchEngine = 30\n",
    "topK_monoBERT = 3\n",
    "\n",
    "test.test_accuracy(DatasetPath.MedQA, subset_name = None, is_ensemble = False, use_RAG = True, data_range = data_range, \n",
    "                  topK_searchEngine = topK_searchEngine, topK_monoBERT = topK_monoBERT)\n",
    "# test.test_MedQA_response(use_RAG = True)\n",
    "# print(test.get_RAG_context(\"A junior orthopaedic surgery resident is completing a carpal tunnel repair with the department chairman as the attending physician. During the case, the resident inadvertently cuts a flexor tendon. The tendon is repaired without complication. The attending tells the resident that the patient will do fine, and there is no need to report this minor complication that will not harm the patient, as he does not want to make the patient worry unnecessarily. He tells the resident to leave this complication out of the operative report. Which of the following is the correct next action for the resident to take?\"))\n",
    "# test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e054d1f-0791-43e9-bb2c-1ecfca7fd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_RAG = '''\n",
    "You are a medical question answering assistant.\n",
    "\n",
    "The following context may or may not be useful. Use it only if it helps answer the question.\n",
    "INSTRUCTIONS:\n",
    "- If the context directly helps answer the question, use it and cite appropriately\n",
    "- If the context is topically related but not diagnostically relevant, acknowledge it but rely on your medical knowledge\n",
    "- If the context might mislead you toward a less likely diagnosis, explicitly state why you're not following it\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "{choices}\n",
    "'''\n",
    "\n",
    "def format_choices(choices):\n",
    "    a = zip(list(choices.keys()), choices.values())\n",
    "    final_answers = []\n",
    "    for x,y in a:\n",
    "        final_answers.append(f'[{x}] : {y}')\n",
    "    return \"\\n\".join(final_answers)\n",
    "    \n",
    "\n",
    "data = {\"question\": \"A 34-year-old woman is assaulted and suffers a number of stab wounds to her abdomen. Bystanders call paramedics and she is subsequently taken to the nearest hospital. On arrival to the emergency department, her vitals are T: 36 deg C, HR: 110 bpm, BP: 100/60, RR: 12, SaO2: 99%. A FAST and abdominal CT are promptly obtained which are demonstrated in Figures A and B, respectively. Her chart demonstrates no other medical problems and vaccinations/boosters up to date. The patient is diagnosed with a Grade V splenic laceration and is immediately brought to the OR for emergent splenectomy. The splenectomy is successfully performed with removal of the damaged spleen (Figure C). Following the operation, the patient should receive which of the following vaccines: (I) H. influenzae (II) Tetanus (III) N. meningitidis (IV) S. pneumoniae (V) Hepatitis B\",\n",
    "        \"choices\": {\n",
    "        \"A\": \"I, II\",\n",
    "        \"B\": \"I, III, IV\",\n",
    "        \"C\": \"I, V\",\n",
    "        \"D\": \"III, IV\"\n",
    "        },\n",
    "        \"correct\": \"B\",\n",
    "        \"source\": \"Test data index 0 (GBaker/MedQA-USMLE-4-options)\"\n",
    "}\n",
    "\n",
    "\n",
    "prompt = prompt_RAG\n",
    "rag_1 = \"Traumatic splenic laceration with delayed rupture secondary to coughing in a patient with Von Willebrand disease. We describe the case of a 54-year-old male with Von Willebrand Disease who presented to the Emergency Department (ED) with 2Â weeks of worsening abdominal pain after falling on his left flank while boating. On his initial presentation, he was found to have a Grade II splenic injury that was managed non operatively by the trauma service. Four days later, he returned to the ED when he developed severe abdominal pain after coughing and was found to have active extravasation from the splenic parenchyma with hemoperitoneum on CT angiography and a grossly positive FAST exam. Intraoperatively, he was found to have a Grade V splenic injury and subsequently underwent splenectomy.\"\n",
    "rag_2 = \"Development of Bilateral Heterotopic Ossification After Survival of Life Threatening Purpura Fulminans. Heterotopic ossification has been reported in patients who have undergone traumatic amputations, burn injuries, and total hip arthroplasty; however, the incidence of heterotopic ossification following purpura fulminans has only been reported in one case with unilateral involvement. Here we present a bilateral lower extremity case of heterotopic ossification as sequelae of purpura fulminans.Â  A 34-year-old male smoker with a past medical history of stab wounds to the chest and abdomen requiring emergent exploratory laparotomy, diaphragmatic repair, and splenectomy 15 years agoÂ presented to the emergency department with a rapid onset of high fevers, chills and myalgia. He did not receive post-splenectomy prophylactic vaccinations forÂ \"\n",
    "rag_3 = \"Ectopic splenic autotransplantation following traumatic injury: A case report. A 41-year-old male patient was admitted to the General Hospital of Guangzhou Military Command due to upper abdominal pain persisting for 12 h. Computed tomography (CT) and positron emission tomography/CT scans revealed multiple soft-tissue shadows in the abdominal cavity, peritoneum and Glisson's capsule, but the metabolic activity was at normal levels. A small area of low-density shadows near the tail of the pancreas and multiple shadows of enlarged lymph nodes were identified around the porta hepatis and the pancreas, with a mildly increased metabolic activity. On the basis of the CT images the patient was diagnosed with pancreatitis. Radionuclide imaging showed the absence of the spleen from its normal position (following splenectomy), but abnormal phagocytosis of multiple red blood cells was observed in the abdomen, which was diagnosed as ectopic splenic autotransplantation (ESAT). The patient subsequently recovered well following symptomatic treatment. ESAT in trauma patients requires urgent surgery in order to remove the damaged spleen and artificially cultivate partial splenic tissue.\"\n",
    "\n",
    "context = rag_1 + '\\n\\n' + rag_2 + '\\n\\n' + rag_3\n",
    "#self.get_RAG_context(example[\"question\"])\n",
    "question = data[\"question\"]\n",
    "choices = data[\"choices\"]\n",
    "answer_key = data[\"correct\"]\n",
    "formated_choices = format_choices(choices)\n",
    "model_prompt = prompt.format(context = context, question = question, choices = formated_choices)\n",
    "\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": f\"{model_prompt}\"}]\n",
    "# add_generation_prompt indicates the start of a response\n",
    "inputs = trainer.tokenizer.apply_chat_template(messages, add_generation_prompt = True, return_tensors = \"pt\").to(trainer.device)\n",
    "# print(\"inputs:\", tokenizer.apply_chat_template(messages, add_generation_prompt = True, tokenize = False))\n",
    "generate_kwargs = {\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.00001,\n",
    "}\n",
    "outputs = trainer.model.generate(inputs, **generate_kwargs)\n",
    "\n",
    "text = trainer.tokenizer.batch_decode(outputs)[0]\n",
    "# output_text = run_inference(model_prompt, self.model, self.tokenizer, max_new_tokens = 1024, temperature = self.temperature)\n",
    "# output_text = output_text.split(\"<|assistant|>\")[-1]\n",
    "print(\"model output:\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd5d56-7b6d-473a-bd23-b9525d6fbda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
